{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ed1284-8a58-4e89-a4b3-8ca65317ee58",
   "metadata": {},
   "source": [
    "![image](https://github.com/kbigdata005/ml/assets/139095086/bf605d7d-2b6d-4250-81b4-ab95dde835a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc92c3-594d-4820-a4eb-79f5aaa2e55c",
   "metadata": {},
   "source": [
    "```\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    padding='valid',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    groups=1,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    " tf.keras.layers.MaxPooling2D(\r\n",
    "    pool_size=(2, 2),\r\n",
    "    strides=None,\r\n",
    "    padding='valid',\r\n",
    "    data_format=None,\r\n",
    "    **kw)\n",
    "\n",
    " tf.keras.layers.Dropout(\r\n",
    "    rate, noise_shape=None, seed=None, **kwargs\n",
    "\r\n",
    "\n",
    " tf.keras.layers.Flatten(\r\n",
    "    data_format=None, **kwargs\r\n",
    "\n",
    "'''\n",
    ")\n",
    ")\n",
    ")rgs\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3ff000a-9b69-49e9-a0ce-3dbe5d4517a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D , Dropout  , Flatten , Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
    "import os\n",
    "\n",
    "(X_train , y_train ) , (X_test , y_test) =  mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000 , 28,28,1) / 255\n",
    "X_test = X_test.reshape(10000 , 28,28,1) /255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64fb4fce-b436-4d6e-b702-404a793792e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93758292-6322-443e-b29c-9c65d522cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 구조\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32 ,kernel_size=(3,3) , padding='same' ,activation='relu' ))\n",
    "model.add(Conv2D(filters=64 ,kernel_size=(3,3)  ,activation='relu' ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512 , activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(10 , activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15408626-adb1-4f33-97f3-546e24a6cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9704\n",
      "Epoch 1: val_loss improved from inf to 0.04394, saving model to ./model\\01 - 0.0439.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 183s 612ms/step - loss: 0.0987 - accuracy: 0.9704 - val_loss: 0.0439 - val_accuracy: 0.9844\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9867\n",
      "Epoch 2: val_loss improved from 0.04394 to 0.03173, saving model to ./model\\02 - 0.0317.hdf5\n",
      "300/300 [==============================] - 172s 572ms/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 0.0317 - val_accuracy: 0.9889\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9910\n",
      "Epoch 3: val_loss did not improve from 0.03173\n",
      "300/300 [==============================] - 173s 578ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.0384 - val_accuracy: 0.9875\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 4: val_loss did not improve from 0.03173\n",
      "300/300 [==============================] - 172s 574ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0348 - val_accuracy: 0.9891\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9939\n",
      "Epoch 5: val_loss improved from 0.03173 to 0.03074, saving model to ./model\\05 - 0.0307.hdf5\n",
      "300/300 [==============================] - 157s 525ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0307 - val_accuracy: 0.9901\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9959\n",
      "Epoch 6: val_loss did not improve from 0.03074\n",
      "300/300 [==============================] - 164s 546ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0337 - val_accuracy: 0.9896\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 7: val_loss did not improve from 0.03074\n",
      "300/300 [==============================] - 164s 548ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0352 - val_accuracy: 0.9896\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 8: val_loss improved from 0.03074 to 0.03051, saving model to ./model\\08 - 0.0305.hdf5\n",
      "300/300 [==============================] - 166s 552ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0305 - val_accuracy: 0.9908\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 9: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 164s 548ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0370 - val_accuracy: 0.9903\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 10: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 164s 548ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0363 - val_accuracy: 0.9921\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 11: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 174s 579ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0452 - val_accuracy: 0.9892\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 12: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 151s 503ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0389 - val_accuracy: 0.9903\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 13: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 153s 511ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0340 - val_accuracy: 0.9913\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 14: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 151s 505ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0354 - val_accuracy: 0.9907\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 15: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 158s 528ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0384 - val_accuracy: 0.9916\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 16: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 142s 472ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0411 - val_accuracy: 0.9898\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 17: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 131s 437ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0414 - val_accuracy: 0.9920\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 18: val_loss did not improve from 0.03051\n",
      "300/300 [==============================] - 130s 433ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0415 - val_accuracy: 0.9908\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0415 - accuracy: 0.9908\n",
      "\n",
      " Test Accuracy : 0.9908\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m y_vloss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m y_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 18\u001b[0m x_len \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(y_loss))\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_len, y_vloss, marker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTestset_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_len, y_loss, marker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainset_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"./model/\"\n",
    "if not os.path.exists(MODEL_DIR) : \n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = './model/{epoch:02d} - {val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose = 1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data = (X_test, y_test), \n",
    "                    epochs=30, batch_size=200, verbose = 1, callbacks =[early_stopping_callback, checkpointer])\n",
    "\n",
    "print(\"\\n Test Accuracy : %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker = '.', c = 'red', label = 'Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker = '.', c = 'blue', label = 'Trainset_loss')\n",
    "\n",
    "plt.legend(loc = 'upper right')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c3ea24-c676-45e2-8040-c9c1ab4566fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
