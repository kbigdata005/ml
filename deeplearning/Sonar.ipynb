{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923c1238-b3b6-467a-a09c-a94c8d59ccb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      V10  ...     V52     V53     V54     V55     V56     V57     V58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      V59     V60  Class  \n",
       "0  0.0090  0.0032      1  \n",
       "1  0.0052  0.0044      1  \n",
       "2  0.0095  0.0078      1  \n",
       "3  0.0040  0.0117      1  \n",
       "4  0.0107  0.0094      1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/Sonar.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8490559-7526-4234-87e4-da530fb99b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 2s 5ms/step - loss: 0.6921 - accuracy: 0.5096\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6686 - accuracy: 0.6058\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6394\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.6201 - accuracy: 0.7019\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 0.5899 - accuracy: 0.7308\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7260\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7788\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5008 - accuracy: 0.7596\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.7885\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.8029\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8125\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.4246 - accuracy: 0.8173\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.8413\n",
      "Epoch 14/200\n",
      "20/42 [=============>................] - ETA: 0s - loss: 0.3781 - accuracy: 0.8600"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# result\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mevaluate(X,y)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# 고정\n",
    "tf.random.set_seed(3)\n",
    "# X,y\n",
    "X=df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]\n",
    "#모델\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history = model.fit(X,y, epochs=200, batch_size=5)\n",
    "# result\n",
    "print(f'Accuracy: {model.evaluate(X,y)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbbad19d-e972-4a70-ad31-3b10eab50432",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4b58247-d179-4048-ac06-37a8b4d18803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6786630153656006,\n",
       "  0.6572908163070679,\n",
       "  0.6418377161026001,\n",
       "  0.6210170388221741,\n",
       "  0.5973927974700928,\n",
       "  0.5791963934898376,\n",
       "  0.5501459836959839,\n",
       "  0.5219172239303589,\n",
       "  0.5084238648414612,\n",
       "  0.48312821984291077,\n",
       "  0.47312381863594055,\n",
       "  0.44765859842300415,\n",
       "  0.4375212490558624,\n",
       "  0.4280256927013397,\n",
       "  0.41941335797309875,\n",
       "  0.41778215765953064,\n",
       "  0.40108662843704224,\n",
       "  0.3978254497051239,\n",
       "  0.39703840017318726,\n",
       "  0.38467642664909363,\n",
       "  0.375296413898468,\n",
       "  0.37378838658332825,\n",
       "  0.35916632413864136,\n",
       "  0.3576893210411072,\n",
       "  0.3546620011329651,\n",
       "  0.34167078137397766,\n",
       "  0.34631073474884033,\n",
       "  0.33934324979782104,\n",
       "  0.3319559693336487,\n",
       "  0.3228967785835266,\n",
       "  0.3155912756919861,\n",
       "  0.33356335759162903,\n",
       "  0.2976379692554474,\n",
       "  0.3099733591079712,\n",
       "  0.29239165782928467,\n",
       "  0.2917526066303253,\n",
       "  0.2834264039993286,\n",
       "  0.2898707389831543,\n",
       "  0.2687162160873413,\n",
       "  0.2661121189594269,\n",
       "  0.2706163227558136,\n",
       "  0.2554616630077362,\n",
       "  0.2679947316646576,\n",
       "  0.2739011347293854,\n",
       "  0.2518027126789093,\n",
       "  0.24160470068454742,\n",
       "  0.23605571687221527,\n",
       "  0.23589716851711273,\n",
       "  0.24225156009197235,\n",
       "  0.23118044435977936,\n",
       "  0.21529684960842133,\n",
       "  0.2109103798866272,\n",
       "  0.2201322466135025,\n",
       "  0.21483244001865387,\n",
       "  0.2078300416469574,\n",
       "  0.20529741048812866,\n",
       "  0.1959080547094345,\n",
       "  0.19521857798099518,\n",
       "  0.1972687989473343,\n",
       "  0.19937525689601898,\n",
       "  0.1881026327610016,\n",
       "  0.19455868005752563,\n",
       "  0.17629040777683258,\n",
       "  0.17492835223674774,\n",
       "  0.17065802216529846,\n",
       "  0.16369770467281342,\n",
       "  0.16981874406337738,\n",
       "  0.16283582150936127,\n",
       "  0.16305619478225708,\n",
       "  0.15082386136054993,\n",
       "  0.15692001581192017,\n",
       "  0.1496550589799881,\n",
       "  0.15119759738445282,\n",
       "  0.15444205701351166,\n",
       "  0.14325302839279175,\n",
       "  0.14309991896152496,\n",
       "  0.14137504994869232,\n",
       "  0.1354532539844513,\n",
       "  0.13893520832061768,\n",
       "  0.12082608044147491,\n",
       "  0.11936634033918381,\n",
       "  0.12085871398448944,\n",
       "  0.11321524530649185,\n",
       "  0.11301939934492111,\n",
       "  0.11105750501155853,\n",
       "  0.12109921872615814,\n",
       "  0.10573974996805191,\n",
       "  0.14723747968673706,\n",
       "  0.10225813090801239,\n",
       "  0.10080736130475998,\n",
       "  0.09814655780792236,\n",
       "  0.10719916224479675,\n",
       "  0.10315094888210297,\n",
       "  0.09151982516050339,\n",
       "  0.0890677273273468,\n",
       "  0.09363028407096863,\n",
       "  0.08836910128593445,\n",
       "  0.08347098529338837,\n",
       "  0.09292511641979218,\n",
       "  0.08308017253875732,\n",
       "  0.08124706149101257,\n",
       "  0.07619655132293701,\n",
       "  0.07614864408969879,\n",
       "  0.07461194694042206,\n",
       "  0.07590743899345398,\n",
       "  0.07737413048744202,\n",
       "  0.07198803871870041,\n",
       "  0.067233607172966,\n",
       "  0.06217937916517258,\n",
       "  0.07104979455471039,\n",
       "  0.07305639982223511,\n",
       "  0.06267525255680084,\n",
       "  0.06295636296272278,\n",
       "  0.05686319246888161,\n",
       "  0.05520235002040863,\n",
       "  0.055327560752630234,\n",
       "  0.055012285709381104,\n",
       "  0.05716075748205185,\n",
       "  0.0523286797106266,\n",
       "  0.052626773715019226,\n",
       "  0.04687771573662758,\n",
       "  0.043115317821502686,\n",
       "  0.04391976073384285,\n",
       "  0.041413627564907074,\n",
       "  0.03926882892847061,\n",
       "  0.04011567309498787,\n",
       "  0.04000405594706535,\n",
       "  0.040220506489276886,\n",
       "  0.040340326726436615,\n",
       "  0.03599991649389267,\n",
       "  0.036088597029447556,\n",
       "  0.03476746380329132,\n",
       "  0.03126534819602966,\n",
       "  0.031224701553583145,\n",
       "  0.028504908084869385,\n",
       "  0.027358802035450935,\n",
       "  0.025952467694878578,\n",
       "  0.027172259986400604,\n",
       "  0.027279892936348915,\n",
       "  0.027338353917002678,\n",
       "  0.026124069467186928,\n",
       "  0.030894862487912178,\n",
       "  0.025706039741635323,\n",
       "  0.027682460844516754,\n",
       "  0.028029033914208412,\n",
       "  0.024639464914798737,\n",
       "  0.019079076126217842,\n",
       "  0.020066529512405396,\n",
       "  0.01783415488898754,\n",
       "  0.01718616485595703,\n",
       "  0.01693863980472088,\n",
       "  0.016932155936956406,\n",
       "  0.017870385199785233,\n",
       "  0.017354601994156837,\n",
       "  0.01559479534626007,\n",
       "  0.014834965579211712,\n",
       "  0.013874854892492294,\n",
       "  0.015022499486804008,\n",
       "  0.014437436126172543,\n",
       "  0.013478879816830158,\n",
       "  0.012248365208506584,\n",
       "  0.012139381840825081,\n",
       "  0.013578860089182854,\n",
       "  0.014593302272260189,\n",
       "  0.012349570170044899,\n",
       "  0.011073396541178226,\n",
       "  0.010115569457411766,\n",
       "  0.01825837232172489,\n",
       "  0.01569238491356373,\n",
       "  0.01276514120399952,\n",
       "  0.012165517546236515,\n",
       "  0.009947159327566624,\n",
       "  0.00868743471801281,\n",
       "  0.008123175241053104,\n",
       "  0.019900301471352577,\n",
       "  0.015737418085336685,\n",
       "  0.013587593100965023,\n",
       "  0.008113021031022072,\n",
       "  0.007459456101059914,\n",
       "  0.007143172435462475,\n",
       "  0.007547546643763781,\n",
       "  0.007052082102745771,\n",
       "  0.006611604709178209,\n",
       "  0.007107307203114033,\n",
       "  0.006541468668729067,\n",
       "  0.00595718203112483,\n",
       "  0.007627510000020266,\n",
       "  0.006339711602777243,\n",
       "  0.005886229686439037,\n",
       "  0.0058525619097054005,\n",
       "  0.0051139225251972675,\n",
       "  0.005616885609924793,\n",
       "  0.0071915932931005955,\n",
       "  0.005424850154668093,\n",
       "  0.00481492979452014,\n",
       "  0.005023517645895481,\n",
       "  0.004302977118641138,\n",
       "  0.0041804020293056965,\n",
       "  0.004732891451567411,\n",
       "  0.004096883349120617],\n",
       " 'accuracy': [0.6153846383094788,\n",
       "  0.6394230723381042,\n",
       "  0.6634615659713745,\n",
       "  0.745192289352417,\n",
       "  0.7596153616905212,\n",
       "  0.7211538553237915,\n",
       "  0.7692307829856873,\n",
       "  0.75,\n",
       "  0.7692307829856873,\n",
       "  0.7836538553237915,\n",
       "  0.7932692170143127,\n",
       "  0.817307710647583,\n",
       "  0.807692289352417,\n",
       "  0.8028846383094788,\n",
       "  0.807692289352417,\n",
       "  0.817307710647583,\n",
       "  0.817307710647583,\n",
       "  0.8221153616905212,\n",
       "  0.8317307829856873,\n",
       "  0.8028846383094788,\n",
       "  0.8461538553237915,\n",
       "  0.8317307829856873,\n",
       "  0.8413461446762085,\n",
       "  0.8509615659713745,\n",
       "  0.8413461446762085,\n",
       "  0.8605769276618958,\n",
       "  0.8365384340286255,\n",
       "  0.8269230723381042,\n",
       "  0.8461538553237915,\n",
       "  0.8509615659713745,\n",
       "  0.8653846383094788,\n",
       "  0.8653846383094788,\n",
       "  0.875,\n",
       "  0.879807710647583,\n",
       "  0.8894230723381042,\n",
       "  0.8846153616905212,\n",
       "  0.9134615659713745,\n",
       "  0.879807710647583,\n",
       "  0.9134615659713745,\n",
       "  0.8942307829856873,\n",
       "  0.9134615659713745,\n",
       "  0.9182692170143127,\n",
       "  0.8942307829856873,\n",
       "  0.8846153616905212,\n",
       "  0.8942307829856873,\n",
       "  0.9182692170143127,\n",
       "  0.9230769276618958,\n",
       "  0.9086538553237915,\n",
       "  0.9134615659713745,\n",
       "  0.9471153616905212,\n",
       "  0.9230769276618958,\n",
       "  0.932692289352417,\n",
       "  0.9086538553237915,\n",
       "  0.9086538553237915,\n",
       "  0.9182692170143127,\n",
       "  0.9182692170143127,\n",
       "  0.9519230723381042,\n",
       "  0.9471153616905212,\n",
       "  0.942307710647583,\n",
       "  0.9375,\n",
       "  0.942307710647583,\n",
       "  0.9086538553237915,\n",
       "  0.9567307829856873,\n",
       "  0.9519230723381042,\n",
       "  0.9567307829856873,\n",
       "  0.9519230723381042,\n",
       "  0.942307710647583,\n",
       "  0.9615384340286255,\n",
       "  0.9567307829856873,\n",
       "  0.9711538553237915,\n",
       "  0.942307710647583,\n",
       "  0.9663461446762085,\n",
       "  0.9567307829856873,\n",
       "  0.9567307829856873,\n",
       "  0.9663461446762085,\n",
       "  0.9519230723381042,\n",
       "  0.9711538553237915,\n",
       "  0.9711538553237915,\n",
       "  0.9519230723381042,\n",
       "  0.9711538553237915,\n",
       "  0.9759615659713745,\n",
       "  0.9711538553237915,\n",
       "  0.9855769276618958,\n",
       "  0.9711538553237915,\n",
       "  0.9759615659713745,\n",
       "  0.9711538553237915,\n",
       "  0.9759615659713745,\n",
       "  0.9278846383094788,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9615384340286255,\n",
       "  0.9663461446762085,\n",
       "  0.9807692170143127,\n",
       "  0.9807692170143127,\n",
       "  0.9711538553237915,\n",
       "  0.9855769276618958,\n",
       "  0.9807692170143127,\n",
       "  0.9855769276618958,\n",
       "  0.9807692170143127,\n",
       "  0.9855769276618958,\n",
       "  0.9855769276618958,\n",
       "  0.9855769276618958,\n",
       "  0.9903846383094788,\n",
       "  0.9807692170143127,\n",
       "  0.9903846383094788,\n",
       "  0.9903846383094788,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  0.9903846383094788,\n",
       "  0.9903846383094788,\n",
       "  0.9903846383094788,\n",
       "  0.9903846383094788,\n",
       "  0.9903846383094788,\n",
       "  0.995192289352417,\n",
       "  0.9855769276618958,\n",
       "  0.995192289352417,\n",
       "  0.9903846383094788,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  1.0,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  0.9903846383094788,\n",
       "  1.0,\n",
       "  0.995192289352417,\n",
       "  0.995192289352417,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1f39664-63d5-4437-a8a0-660d80f270ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24f3b2d65d0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAH5CAYAAABJUkuHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqJklEQVR4nO3dd3hUVbvG4WcSSAJCQg8EgoCioPRqQKxIEbGhIqAodkRpFkBF7ChYsCAonwULgqiACqKCgCBBlCIgUqUJJPSEnrbPH++ZTEIKSUgymcnvvq59zZ5dZtbMN4eTx7XWu1yO4zgCAAAAAD8S4O0GAAAAAEB+I+gAAAAA8DsEHQAAAAB+h6ADAAAAwO8QdAAAAAD4HYIOAAAAAL9D0AEAAADgd0p4uwE5kZKSol27dqls2bJyuVzebg4AAAAAL3EcR4cPH1ZERIQCArLut/GJoLNr1y5FRkZ6uxkAAAAAiogdO3aoRo0aWZ73iaBTtmxZSfZhQkNDvdwaAAAAAN4SHx+vyMjI1IyQFZ8IOu7haqGhoQQdAAAAAKed0kIxAgAAAAB+h6ADAAAAwO8QdAAAAAD4HYIOAAAAAL9D0AEAAADgdwg6AAAAAPwOQQcAAACA3yHoAAAAAPA7BB0AAAAAfoegAwAAAMDvEHQAAAAA+B2CDgAAAAC/Q9ABAAAA4HcIOgAAAAD8Tq6Dzq+//qquXbsqIiJCLpdL06dPP+098+fPV7NmzRQcHKxzzz1XH3/8cR6aCgAAAAA5k+ugc/ToUTVu3Fhjx47N0fVbtmxRly5ddPnll2vlypUaOHCg7rnnHv3444+5biwAAAAA5ESJ3N7QuXNnde7cOcfXjx8/XrVr19Zrr70mSapfv74WLVqkN954Qx07dszt2wMAAADAaeU66ORWdHS02rdvn+5Yx44dNXDgwCzvOXnypE6ePJn6PD4+vqCaBwBAsbZtm/Tcc1JIiDR8uFS1as7ucxxp1Chp7Vpp2DCpXr2sr12yRHrlFWnv3vxpMwDv6NVL6tvX263IuQIPOjExMQoPD093LDw8XPHx8Tp+/LhKlSqV4Z6RI0fq2WefLeimAQBQbB05Ir38svTqq5L7vy1+8on0xBPSoEEWfLLz2mvS0KG2P2mS1K+f9PTTUoUKnmv++8+u+fzzgvkMAApX27bebkHuFHjQyYthw4Zp8ODBqc/j4+MVGRnpxRYBAIqLVassAMTGeo6VLy898ogUFXXmr+840qxZ0qefSv37S23apD+/dav01FPSJZdId98tBQZ6zv3xhzR6tLR//5m34++/PZ/x8sulY8ek33+3oDNunFS3rufa88+XnnxSql7dnn/5pfTYY7bfvLm0bJn05pv2mZo08XzOJUuk48cll0u6806pSxfbB+CbzjvP2y3InQIPOlWrVlVs2v9vISk2NlahoaGZ9uZIUnBwsIKDgwu6aQAApNqzx4Zu/e9/UkpKxvNffy317GkhKK//7W3tWmnwYMldj+eHH6TffpMaNLDn+/dLnTpJ69dbL8g770hjxtiwsGHDrMclP9WpYz0z111nwWTSJGnIEGnHDtvcfvlFmjjRzl10kXT77Xa8f38LOD//bL1Af/9t16bVtq1d07x5/rYdAE7H5TiOk+ebXS5NmzZN119/fZbXDBkyRLNmzdLq1atTj/Xs2VMHDhzQ7Nmzc/Q+8fHxCgsLU1xcnEJDQ/PaXABAMbJokYWWu+6y3pG0YmMt1Ozcac8dxwKHe0roLbfYH//u3oc5c6SPPrLrSpWSLr1UCshl3dKEBGnePCk5WSpZUqpVS9q40ULTkiU25Ouqq6zd1apJJ05IBw/avUFBdr9kISMXNYGydNZZUseO0qn/XfHoUemnn+z9JSkpSXrvPft+0rr+eumrrzw9TklJdl9cnOeaqlWlyy6jFwdA/sppNsh10Dly5Ig2bdokSWratKlef/11XX755apQoYJq1qypYcOGaefOnfrk//+z05YtW9SgQQP169dPd911l3755Rf1799fM2fOzHHVNYIOACCntm2THn/chldJ9gf9woVS06b2/OhRCyrLlmW8t1kz60Fp1y7jueXLpYED7bXOxPXX2/CzChVs2Nr69Tbc69xzLTiEhVmoqFpVeuYZG0aWnGzD5saMkVq1OrP3zwvHse/z8cel7dul1q2t56Z06cJvCwAUWNCZP3++Lr/88gzH77jjDn388ce68847tXXrVs2fPz/dPYMGDdLatWtVo0YNDR8+XHfeeWe+fxgAKA5+/FGaPVt6/nmpTBlvtyZvEhKs0lflytIDD6TvVYiN9QSBAQMsqLgdPGhDrdauzfx1k5JsGNWJE9bjUquW9O+/1kOyZIkUESHdcIP0/fdSpUrSSy9Z74okValiPRxp58ScynHsD/y0w7pyo359CwluW7bYULA9e+x5yZL2v+0VV3iu2bDBwlv79t7vGTl+3D7/pZf67m8PgO8rsKDjDQQdADCxsTYZND7e5nr8/xJlPmfUKJvvIUnnnGOVvzp1kt56S3rhBenwYTtXvbrNieneXZowwap65WQi/uWXS2+8YUHn4oulNWukCy+0kPHhh1ZR7Jdf8qe4wJn64w8LDseP2xwc9/wXAEDmCDoA4IfuuUf64APbL1FCWr06+/VLcmrbNgsYR45kfj4oyIJV48bZv86330qTJ1vPh2S9I3feab0Rbrt3W1g7ckQqW9YTakJDPXNkmje3QLN1a8ZzF14o3X+/tSkz55wjXXmlp/djxw7rNdm1y567XDZE7MYbs/8shWnTJvu8aXt7AACZI+gAgJ9Ztkxq2dJCRKNGVga5UycrVXymQ5oGDbL5H9mJipIWL876/H//WRniY8fSHz91ONadd1oFr1atbJjZK69Yz9TJkzbE7OWXpdtus+Ftb7whvfiizaupWNGGu913n4W83Fi50ubdHDlir5nNmtUAgCKOoAMAPio52YYwbdxoc1TCwy3cXHyxBY2ePW2S+oUXSomJ0nffSddcY9fMnGmVve6/P+N6B/PmWSh67DGbj5LWVVdZZbHbb5datMjYniFD7L1+/z3ryfA9e0pffGG9Mb1727GffrI2uSfYHzlivSuSzZlx92Bs3WrVxq6/PuPcj927rW3XXGPr2eTVpk3Wc3XllXl/DQCA9xF0AMAHzZ9vvQ1//WXPy5a1xSMrVbLFI0uXtipdNWpY+Bg1yqp1TZ5sK9DPmWP3lSghPfywzWnZt8/CzfTpdu7ZZ+14WpGR1iPz228ZF7CUpDvusPDVs2fmq9wvWmQ9Ji6X9OefVr1MsqIA7pLJkZH2OVassCA0cWI+fGEAgGKHoAMAp7F4sf0B/sgj2VfaOhOffZa+HHFwsC2yeO656a87csTCxDff2PNy5aSzz/YEHrcXXrAV6iWb23LeeVJMjOd8UJCFjCVL7HmFCnZdYqLnmm7dbI6K2+HDNgdGsnkiFSpk/BzLl1tPTYkS1vtSvbrnXHKy9fIsX25ziCZMSH/v/v0WnjZssOdlyth+tWoZ3wcAgNPJaTbI5XJnAOAf9u+3oVBDhtiK9wVhwwYbCvb++57t7belfv0yXjtypIWcwEA7v3GjBYePP/YEgtq1LZS5lS1r81ncunWT1q2ToqOlH36wUsYHDljI6djRVqeXrIBBWuvX22OVKpmHHMnC0yWXWPnmd99Nf+6jj6ytYWE2n+ZUFSvakLnKle35U08RcgAABY8eHQDF0oMP2kKMUubDqNassbkl/fplv16I41i54ooVbX5JWg89JI0dawUErr3WAscLL0gpKdLff0sXXGDXHTsm1axp4WvyZCulnNaRI9LUqbbCfO3aGd//669tfZhTh5wlJkpTptgcn/btrTR1tWq2vsyRI1KpUnbdp5/ad3DppTZ0LivTplmlsooVrZJZqVI23K1ZM2nvXun1162oQVY2brTerTvuKLgeNACA/2PoGgBkYdUqqWlTCxyS9TTExFgAcGvZ0uaadOpkk/2zqvI1cqT0xBN274oVVg1NsoUta9SwEDN3rqfi2I03WmC4/35p/Hg7NmGCVRKrVcsmzBdUCHAc+6z791sFN/c8mieesM+Rtk2ZSU62IXdbt1rv0KFDVjHt2DErcb1qlWfxTQAACgpD1wBAViXsvfesPLFkf+wPGGAh54YbbG7K3r0Watw2bPA8nz3ben8y+09CkyZZSJDs9QYM8Fz3wQcWABo0sMUr3dxljT/5xAKH43jKOj/8cMH2dLhcUsOGtp92+Nq6dfZYv3729wcGWhsl+6wjRthnbNvWCh0QcgAARQlBB4DfOnLEemQeeMAm7X/6qU3Cnz9fCgmx9VQ6dLBrZ8703PfFF/ZYp4711EyYkH4ujCQtWCD16WP7vXvb682fb8PIkpJsLo5kwSbtGjft2llv0vHj9rpz5khr19rwuLvvLoAv4RSZBZ1//rHH0wUdydroHspXs6YNtVu40NbPAQCgKMnlkmsAUDhiYuyP6BtvtD+o09q2zeasXHttxrVi0po40YZXSdKuXRZI3MPThgyxqmZdulj4mTnTyi47jifojBghxcdbL8YTT9h8lPLl7Zp337UFLbt1s8n4Z58tPf+89OijVlJ5+3YrpdyzZ/o2uVzWG3LnndI779haOJKFprCwM/3WTq9BA3t0B53ERBsuJ9nws9MJC5N+/NHCUc+ennk+AAAUNczRAVAkuSfyh4TYGjBDhljAeOUV6dVXLUykXSumXLn096ek2B/uGzfa9YmJVhHsyBFbz2XdOluTJibGUwFs927bmjWz942NtaFtjzxiE+1PFRVl829KlfLMU9mxw0pInzxp1cWefz7jfSdPWnjbs8eeu1xW+axu3Xz9CjMVHW1FCyIipJ077XuoX1866ywrM5229wkAgKIop9mAHh0AZ2z9epvcfsMN+fdf+Jcvt8cTJywsfPihBZ1du+x4rVo2Kf6NN2xI2ssvpx/69cMPFnLCwmySfZky1osycaKVlS5d2q6rWlVq0cLm5Pzwgw0jk+wa97+do0fb0Ky///a8fqVKFsbcn7d0abvu1lstyJQoIfXtm/lnCw62eT/PPGPPu3QpnJAjeXp0du2y0tPuYWv16hFyAAD+hTk6AM7YzTdLvXrZH8tTpmQ+cT83HMfKO0tWDaxWLet92LXL5s18843077+etWL27bOFKtOu7+JeM+aeezxzSqpWtZ4h93Axt6uvtsfvv7fhclL6IWcBAVYV7c03Pdvw4TaMLa1bbrG1Ztz7ERFZf8YHHrDFPSUbylZYypa171Oy4WvuQgQ5GbYGAIAvIegAfu7gQenzz23oVkHYtcsz32P7duvRaNcufRWz3Nq2zYZRlSxpw8b++cfCxVtvWa/KDTdY70OnTtJff0lDh9p9Dz9spaD//lv6+WcLKA89dPr369LFHqdPt3k4oaFS5865b7fLZZXYnnzSepqyEx5uZabff1+68srcv9eZcPfqrFmTu0IEAAD4EoIO4OeGDpVuuy1j1bD8smCBPTZsKD33nA3h+u03W4emTx/PULPccAenevUs7ISESP37W5AJCUl/bcmS0ksv2bC1lBQLWu4SyNdf7+m9yE6LFra+jHtdnW7dMr5PTlWvbouCVqly+muvvlq6997CHzKWtvJaTktLAwDgawg6gJ/78Ud7/OSTMx9Slpn58+3xqqtsONf69dLtt9uxjz+2qmgvvWTllE+1bZs0Y4YnYLi5h625/yA/HZdLGjdO6tjRigLMm2fH3WvWnE5AQPoenB49cnafr3J/r6tWMXQNAOC/CDqAH9u61cKEZCWEly3L//dwB53LLrPHGjUsVC1ZIl10kS3U+eST1mMwdaqFrcOHrVzz+edbr8tHH6V/TXePTk6DjmQ9O19+KTVubM+bNZMuvjjn97uHr4WHp1/g0x+5h6798Yf9bxEYKJ17rnfbBABAfiPoAH7MHULc3OvD5Jddu6QNG6xHpV279Odat5YWL7b5QTVqWOC65RapbVvr5Rk50qqTSVZUIK28BB3J5tb88IM0aJD0wQe5GxLWrZutozNpklVM82fnn2+fMSnJnp9zjqcwAgAA/oKgA/gxd9BxB4bJk6Xk5Px7fff8nKZNM65jI1nQ6NnThkeNGGGlmKOjbe2ac86xY+7XcQ+rS0jwDKdy9zzkRrVqtuZNkya5uy8w0NbjueKK3L+nrwkKSj9Ujfk5AAB/RNAB/Jg76LzwggWRXbukhQs950+csJLKmc2fyQl30HEPW8vKWWfZmjHr11tRgTFjrDLaE09Y8YJ9+zzr12zYYD0NoaG2qCYKRtoQSdABAPgjgg7gp9zzcwIDrZeiWzc7PmmSPSYm2vyYrl09C1fm1qnzc04nMtLKRA8YYItmBgXZULa0r+UettagAQtYFqS0wwIpRAAA8EcEHcBPuXtbWra0BTPdC2B+9ZUND3vwQU9Ftk8/zf2Qtt27rYcms/k5uXHppfaYWdBBwUkbdOjRAQD4I4IO4KdO7W259FKbv3LwoHTdddL//mdllUuXttDiDkY55b6+SZPM5+fklLt97nk6uS0tjbxp1MizT48OAMAfEXQAH+Q4Vip6376srzk16AQGWtUzSZo92x7fesvT05Pbimy5HbaWlZYtrUjB3r3SP//kveIacufss634wujRNh8KAAB/Q9ABfMzq1bY4Z4sWNr/FXaI5rW3bbI5OYKDUpo3nuDvUSNKjj0r9+nkWx/zqq8xfKyv5FXTSztP57jtrt8TQtcLw7LP2OwAAwB8RdIBCFhMjbdmS+/sOHJD69rWhYnPn2rENG6Q33sh4rXtYWYsWUtmynuMtW0pDh1q1s1desWPuIW2HDnnm7GTm0CGr0Pb999KUKfkzP8fNHZbGjbPHatWkihXP/HUBAEDxRdABCkl8vDRkiA0ZatjQel1yo1cvafx4KSVFuukmW3BTstLRu3alvzar3haXy+578UWbnyNZr0/37raf1fC1LVtsHkfXrrbdeqsdb9xYKl8+d58jM+52ur8Thq0BAIAzRdABcigx0eaQZCY52SbRuxe9TMtxbOJ/3brSqFFW8ezoUU+Z55z47z9Pb8ucOdLUqdLjj0sXXWSvNXRo+utzO6zMPaRtxgzpyJH05w4ckDp3lmJjraelZUvboqKk557L+WfIjnuejhtBBwAAnCmCDpBDTz0lXXCB9OWXGc+NGWN/nI8alfHc2LHSvfdKe/ZI551n+1LuJv9PmWKBqV076cor7VhAgBUTkKw89JIl0s6dUu/e1gMTGOiZ+3I6LVpI555rC4d++63n+IkTVqFt/XpbA+fPP6WlS21bvNh6d/JDUFD6uUTMzwEAAGeKoAPkgONIn39u+998k/G8+9hrr1k4cEtKsqpWkvXArF5tc2NKlrR9dynl03H3/rgLB7i1bCn16WP7t95qQerTT+358OHp5+dkx+XyvPaECdKvv9rWu7e0aJFV5Zo1S4qIyNnr5UXa3id6dAAAwJki6AA5sGqV9ZZINiws7RC1o0eth0OyEsmTJ3vOzZghbd8uVapkFa6CgmxOS+fOdj4nvTobNkjLl1sPzU03ZTz/0ksWaLZtk44ds16cP/6QRozI3Wd0B535861AwaWX2hC5kiWladMKvpfFHXRcLus5AwAAOBMEHSAHZs707MfG2lAut8WLrefGbcwYTxAaM8YeH3hACgnxXJN27ZrM5vWk5Q5DHTpIlStnPF+1qvThhxYUJk+WFi60oWi5Vb++NGCAdP75nq1JExs2d8UVuX+93IqKku65x+b9pJ2vAwAAkBclvN0AwBfMmmWPAQFW9Wz+fM9q8u6J/127WqGAv/6y8s5ly9qwr5IlrSx0Wl27SmedZXNpfv/digpkxnGyHraW1k03Zd7bk1vuYOYNgYE2bA4AACA/0KMDnMb+/VJ0tO2758O4w03a/RtukO64w/bffNM2yUo3nzq3pXRp6frrbT+76msrVtjQtZAQz/UAAAA4PYIOcBo//WS9OA0b2uR8yTNPJ+38nMsuk/r3t/0ZMzxzdQYMyPx13T00X36ZfuhbWu5ha1275rywAAAAAAg6wGm55+dcfbXUqpX1rsTGWk9LdLSFlJo1pVq1bJ5Lx44WghITrTBAVvNlOnSQKla015o3L+P5lBRPWHLP6QEAAEDOEHSAbCQnS7Nn236XLhZyoqLs+fz56RfmdLlsf+BAz/1p909VsqRnXs1rr9l7pTV5si0UGhbmqdIGAACAnCHoAGk4jnT4sOf50qU2R6dcOU/AufRSezw16Lh16GBr2lx//enn1Tz4oBQcLP34ozRokKcC22+/SXfdZfv9+tk1AAAAyDmCDvD/kpOlW26xHpS77pJiYjzV1jp2lEr8f41Cd6iZO9czP8cdfiSrzPbFF7b2TInT1DVs1MizwOfbb1vVsw0bpOuuk06etMfnnsuvTwgAAFB8uBzndKt4eF98fLzCwsIUFxen0NBQbzcHfshxpIcflsaO9RwrU8aqo+3ZI02c6ClEcOKE9fCcPGnPIyNtsU730LW8GD1aevxxe43wcAtZLVtaj1Hp0nl/XQAAAH+T02xAjw4g6fXXLeS4XNLIkVLr1tKRIxZyXC6pUyfPtWnn6Ujp5+fk1aOP2jA2x7GQU7u29N13hBwAAIC8Iuig2Js61YKGJL36qjR0qLR4sQ0pa9DAFvusUiX9PWnn5KTdzyuXy9bduesue88ffrCeHQAAAOQNQ9dQbB09Ko0aJb38spSQYEPX3nwzZ70zCxZ4As7mzVKdOgXaVAAAAPy/nGaD00yVBvxPSoo0aZL13Ozcacduvll6442cD0GLipIuucTWwaldu+DaCgAAgLwh6KBYSUqyymrTptnzWrWsEEC3brmbZxMUZL06AAAAKJoIOig2HEfq399CTnCw9PTT0uDBVlwAAAAA/oWgg2Lj1VelceOs5+bzz60XBwAAAP6JqmsoFr780tapkayUNCEHAADAv9GjA7/jONJtt0lffJH+mGRD1wYO9EqzAAAAUIgIOvA7335rVdVO1auX9eYAAADA/zF0DUXK9OlWCe3XX/N2/4kTVmBAskVAY2Js27dP+uwzKTAwv1oKAACAooyggyIjJcXCybZttohnXrzxhvTvv1JEhDRihBQeblvFivnbVgAAABRtBB0UGTNnSps32/5PP0l79+bu/p07pRdftP1XXpHKlMnf9gEAAMB3EHRQZIwZ49lPTpa++ip39w8dKh09KkVF2XwcAAAAFF8EHRS699+XWraUFi3yHFu1SvrlF5tD07+/HUtbNS07iYkWkj77zNbIeestewQAAEDxRdBBofryS+n++6U//5SuvVZat86Ov/mmPd54o/TYYxZUFi6Utm/P/vV++EFq1EgaNMie33+/1KJFwbUfAAAAvoGgg3xx8KB0+eVWDCArixZJt99u++XL2z2dO0tr1kiff27HBw6UatSQ2rWz51OmZP16d90lXX21haXKlaX33pPeeSdfPg4AAAB8HEEH+eLbb6X5861q2qpVGc+vXy9dd52UkCBdf730zz/SOedIW7dKrVtLJ0/acLaoKLu+Z097zGw9HElaulT66CMb6vbII9LGjdJ991E+GgAAAIagg3yxfLk9pqRYr4zjeM7t2WM9NwcOWKj5/HMr+fzDD1b2+dgxu27AAM/cmptukkqUkFau9AxvS8s91K1nT+nVV6WwsIL6ZAAAAPBFBB3kC3fQkaR586RvvrH9Y8ekrl2lLVukOnWs56d0aTtXt6703XdSqVLWu3PzzZ7XqFhR6tDB9k8tSrBzp831kSwcAQAAAKci6OCMpaRYz4skdetmj488YqWee/WyYWYVKlgPTpUq6e+NirIFPv/8UwoKSn/OPXzts89syJvbuHFSUpLN42nevEA+EgAAAHwcQQdnbNMm6cgRKSRE+vBDKTJS2rbNQsj06VJwsDRjhnTeeZnfX7WqVK5cxuPXXWdD0v79V7rnHhsOd/y4NH68nR84sIA+EAAAAHweQQc5tmmThY8ZM9Ifdw9ba9xYCg2VRo+25+vX2+Onn0oXX5z79ytTRpo82QoMfPqpNGKEFSfYv186+2xrCwAAAJAZgg5yZO9eqVMnm2MzbFj6cytW2GPTpvZ4yy1Walqy0JN27k1uderk6cF5/nnp8cdt/+GHqbAGAACArJXwdgNQ9B0/bot7bt5sz//5x4oL1K5tz909Os2a2aPLZYHo339tMc8zdc89Vob6xRetcttZZ0l3333mrwsAAAD/RY8OspWSYot8Llli82jq17fjs2bZo+N4enTcQUeyYWf5EXLcnn9euu0227/vvszn9AAAAABuBB1kKS5Ouvde6euvrSLajBnSnXfaOXfQ2bHD5syUKCE1aFBwbXG5pIkTpd9+k15+ueDeBwAAAP6BoIMMkpOl99+3dW4+/NCOffyxdMkl0tVX2/NffrE1ctzD1i680KqrFaSAAKlNm4xlqAEAAIBTMUfHT6SkWJGA6tWl/v1zfp/jSGPGSD/+6Dm2daunYlq9ena+Y0d7fuGFUs2a0vbttjBoZsPWAAAAAG8j6PiJOXOkUaM8z3Madl58URo+POPxcuWkZ5+V+vaVSpb0HHe5rFdn/HgbvrZ9ux13V1wDAAAAigKCjp+YNMmzP3Cg9bpcf33293z2mSfkDB3qKTRQsqTUoYNUsWLm93XpYkFn5kwpMdGO0aMDAACAosTlOI7j7UacTnx8vMLCwhQXF6fQ0FBvN6fIOXFCCg+X4uOlSy+VFiyQQkJsaNlFF2V+z7x5NhwtMVF67LH0vUGnc/SohaCTJ+25y2XvXabMmX8WAAAAIDs5zQYUI/ADs2ZZ0KhRQ/r5Z+txOXFC6tpVio7OeP38+dINN1jIueWW3FcxO+ssz4KgknTeeYQcAAAAFC15Cjpjx45VrVq1FBISotatW2vp0qXZXj9mzBidf/75KlWqlCIjIzVo0CCdOHEiTw1GRu5haz162LCzyZNtKNm+fVal7LbbpP/+s0U+b77ZQkpcnHTxxVayOSAPvwJ39TWJYWsAAAAoenL9J+6UKVM0ePBgjRgxQsuXL1fjxo3VsWNH7dmzJ9PrJ02apKFDh2rEiBH6559/9MEHH2jKlCl64oknzrjxsJ6c77+3/R497LFMGemnn6Q+fWxY2eefW69L/frSV19ZsOnb1+4LCcnb+3bp4tmnEAEAAACKmlwHnddff1333nuv+vTpowsuuEDjx49X6dKl9aF7wZVTLF68WG3btlXPnj1Vq1YtdejQQT169DhtLxByZvp0mytTr57UpInneMWKtgbOH39IbdtKx4/bdVdeKa1cKb37rhQWlvf3rVNHatTI9i+++Aw+AAAAAFAAchV0EhIStGzZMrVv397zAgEBat++vaIzmwwiqU2bNlq2bFlqsPn33381a9YsXZ127NMpTp48qfj4+HQbMpd22JrLlfF88+bSwoXWe/PjjzaHp2HD/Hnv6dOlH36QoqLy5/UAAACA/JKr8tL79u1TcnKywsPD0x0PDw/XunXrMr2nZ8+e2rdvny6++GI5jqOkpCQ98MAD2Q5dGzlypJ599tncNK1Y2rvX1s+RPMPWMuNypR9qll9q17YNAAAAKGoKvOra/Pnz9dJLL+ndd9/V8uXL9c0332jmzJl6/vnns7xn2LBhiouLS9127NhR0M30SVOnSsnJUosWUt263m4NAAAAUHTkqkenUqVKCgwMVGxsbLrjsbGxqlq1aqb3DB8+XLfffrvuueceSVLDhg119OhR3XfffXryyScVkEnJr+DgYAUHB+emacXOxo3S00/bfs+e3m0LAAAAUNTkqkcnKChIzZs319y5c1OPpaSkaO7cuYrKYqLGsWPHMoSZwMBASZIPrFVaJO3dK3XuLO3fL7VsKd1/v7dbBAAAABQtuerRkaTBgwfrjjvuUIsWLdSqVSuNGTNGR48eVZ8+fSRJvXv3VvXq1TVy5EhJUteuXfX666+radOmat26tTZt2qThw4era9euqYEHOXf8uHTttdLmzTY/5rvvpNKlvd0qAAAAoGjJddDp3r279u7dq6effloxMTFq0qSJZs+enVqgYPv27el6cJ566im5XC499dRT2rlzpypXrqyuXbvqxRdfzL9PUUykpNjin0uWSOXLS7NmSafUhQAAAAAgyeX4wPix+Ph4hYWFKS4uTqGhod5ujtd88IF0zz1SUJCVib7kEm+3CAAAAChcOc0GBV51DfkjLk5yV+R+8UVCDgAAAJAdgo6PeO45ac8e6fzzpf79vd0aAAAAoGgj6PiAdeukt96y/TFjbOgaAAAAgKwRdIo4x5EGDZKSkqRrrpE6dfJ2iwAAAICij6BTBGzaJP30U+bnZs6UZs+WSpaUXn+9cNsFAAAA+CqCThFwyy1Sx47Sjz+mP+44ngIEgwZJdesWftsAAAAAX0TQ8bJjx6SVK23/1B6bX36RVq+WzjpLGjq00JsGAAAA+CyCjpetXWs9N5INX1u71nPuzTft8c47bYFQAAAAADlD0CkkmzdLf/yR8fiaNemfu6urbdokff+97VNOGgAAAMgdgk4h2LdPatVKatNG2rYt/bnVq+2xWTN7/OQTaf9+6e23raenSxfpvPMKt70AAACAryPoFILhw6UDB6xE9MKF6c+5g84DD0hNmkjHj0uvvip9+KEdHzCgUJsKAAAA+AWCTgH76y/p/fc9z5csSX/ePXStYUNp4EDbf/ll6cgR6YILpPbtC6WZAAAAgF8h6BQgx7H5NSkpUrVqdixt0Nm/X9q92/YvvFC69VapShXP+YEDJZer0JoLAAAA+A2CTgGaOlX69VepVCnpyy/t2F9/WUlpyTNsrXZtqWxZKThYevBBO1axonTbbYXfZgAAAMAflPB2A/zVsWPSo4/a/pAhUtu21quze7e0fLl08cWeYWsNGnjuGzhQ2rpVuvZaC0gAAAAAco8enQLy6afSjh1SzZrSY4/ZELTWre2ce/iau0enYUPPfWFh0kcfSTfcULjtBQAAAPwJQaeArFtnj7fcIpUubfsXXWSP2QUdAAAAAGeOoFNAdu2yx+rVPcfSBh3HyXzoGgAAAIAzR9ApIO6gExHhOdaihRQQIO3cKUVHS4cPSyVLsiAoAAAAkN8IOgUksx6ds86SGjWy/QkT7PH886WgoMJtGwAAAODvCDoFwHGs10ZK36MjeYavuctNMz8HAAAAyH8EnQJw8KB08qTtuxcKdXMHHfdaOgQdAAAAIP8RdAqAe9haxYpSSEj6c+4S024UIgAAAADyH0GnAGQ1bE2ywgPlynme06MDAAAA5D+CTgHIrOKaW0CAp1enTBnp7LMLr10AAABAcUHQKQCZVVxLyz1Pp0EDyeUqnDYBAAAAxQlBpwBk16MjSX36SK1aSQMGFF6bAAAAgOKkhLcb4I+ym6Mj2XC1338vvPYAAAAAxQ09OgXgdD06AAAAAAoWQacAnG6ODgAAAICCRdDJZ8nJUkyM7dOjAwAAAHgHQSef7dljYScgQKpSxdutAQAAAIongk4+cw9bq1pVKkGpBwAAAMArCDr5jEIEAAAAgPcRdPLZ6UpLAwAAACh4BJ18RsU1AAAAwPsIOvmMoWsAAACA9xF08hlD1wAAAADvI+jkM4auAQAAAN5H0MlnDF0DAAAAvI+gk49OnpT27bN9gg4AAADgPQSdfLR7tz0GB0sVKni3LQAAAEBxRtDJrfXrpW+/zfRU2mFrLlchtgkAAABAOiW83QCf8ttv0sUXW3fNzp1SSEi608zPAQAAAIoGenRy46KLpBo1pAMHpOnTM5ymtDQAAABQNBB0ciMwULrrLtufMCHDaUpLAwAAAEUDQSe37rrLJuD88ou0eXO6UwxdAwAAAIoGgk5unX221KGD7X/wQbpTDF0DAAAAigaCTl7ce689fvSRlJiYepihawAAAEDRQNDJi65dpcqVpZgYadYsSZLjMHQNAAAAKCoIOnkRFCTdeaft/39RgtWrpcOH7VSNGt5rGgAAAACCTt7dfbc9/vCD9N9/+uILe3r11VLp0t5rFgAAAACCTt6df750ySVSSoqcd8elBp2ePb3bLAAAAAAEnTMzcKAkKfr1aG3bJpUpI11zjXebBAAAAICgc2auv1666CJ9cfIGSdINN0ilSnm3SQAAAAAIOmfG5VLSS6P0pW6RJPVo95+XGwQAAABAIuicsV8S22mPwlVR+9R+5iBvNwcAAACACDpnbNIke7xFU1VyxlfS4sXebRAAAAAAgs6ZOHFCmjbN9nt0ibedxx+31UMBAAAAeA1B5wzMmiXFx0uRkVLbcbdJISHSb79JS5Z4u2kAAABAsUbQOQPuYWu33ioFRFa3HUkaP957jQIAAABA0Mmr+Hjp++9tP3WR0Pvvt8cvv5QOHvRKuwAAAAAQdPJs2jTp5EmpXj2pceP/P9i6tdSokU3e+eQTr7YPAAAAKM4IOnn0xRf22KOH5HL9/0GXy9OrM348RQkAAAAALyHo5MGePdKcObbfo8cpJ2+7TTrrLGndOmnhwkJvGwAAAACCTp5MnSolJ0stWkh1655yMjTUk37ee6/Q2wYAAACAoJMn7mprqUUITuUevvbVV9K+fYXSJgAAAAAeBJ1c2rZNWrzYpuN0757FRS1aSM2aSQkJ0scfF2bzAAAAAIigk2uTJ9vjpZdKERHZXHjfffZI9TUAAACg0BF0cum0w9bcbr5ZKllSWr3aNgAAAACFhqCTC3//La1aZfmlW7fTXFyhgnT11bbvTkcAAAAACgVBJxeqVZPeeksaPNhyzGn16mWPkyZJKSkF2jYAAAAAHi7HKfqrWsbHxyssLExxcXEKDQ31dnNy7vhxKTxcOnxY+vVXqV07b7cIAAAA8Gk5zQZ56tEZO3asatWqpZCQELVu3VpLly7N9vpDhw6pX79+qlatmoKDg3Xeeedp1qxZeXlr31KqlGeM2+efe7ctAAAAQDGS66AzZcoUDR48WCNGjNDy5cvVuHFjdezYUXv27Mn0+oSEBF111VXaunWrvvrqK61fv14TJkxQ9erVz7jxPsE9fG3qVCs3DQAAAKDA5XroWuvWrdWyZUu98847kqSUlBRFRkbq4Ycf1tChQzNcP378eI0ePVrr1q1TyZIl89RInx26JknJyVJkpLR7tzRjhnTttd5uEQAAAOCzCmToWkJCgpYtW6b27dt7XiAgQO3bt1d0dHSm93z77beKiopSv379FB4ergYNGuill15ScnJylu9z8uRJxcfHp9t8VmCgdOutts/wNQAAAKBQ5Cro7Nu3T8nJyQoPD093PDw8XDExMZne8++//+qrr75ScnKyZs2apeHDh+u1117TCy+8kOX7jBw5UmFhYalbZGRkbppZ9LiHr337rRQX5922AAAAAMVAgZeXTklJUZUqVfT++++refPm6t69u5588kmNHz8+y3uGDRumuLi41G3Hjh0F3cyC1ayZdOGF0okT0vvve7s1AAAAgN/LVdCpVKmSAgMDFRsbm+54bGysqlatmuk91apV03nnnafAwMDUY/Xr11dMTIwSspicHxwcrNDQ0HSbT3O5pEcesf0xY6STJ73aHAAAAMDf5SroBAUFqXnz5po7d27qsZSUFM2dO1dRUVGZ3tO2bVtt2rRJKWkWzNywYYOqVaumoKCgPDbbB/XsKUVESLt22QKiAAAAAApMroeuDR48WBMmTNDEiRP1zz//qG/fvjp69Kj69OkjSerdu7eGDRuWen3fvn114MABDRgwQBs2bNDMmTP10ksvqV+/fvn3KXxBcLA0cKDtjx4tpQl+AAAAAPJXidze0L17d+3du1dPP/20YmJi1KRJE82ePTu1QMH27dsVEODJT5GRkfrxxx81aNAgNWrUSNWrV9eAAQM0ZMiQ/PsUvuK++6QXXpD++UeaOVPq2tXbLQIAAAD8Uq7X0fEGn15H51RDhkijRkkXXywtXOjt1gAAAAA+pUDW0UE+GDBACgqSFi2SFi/2dmsAAAAAv0TQKWwREdLtt9v+W295ty0AAACAnyLoeMM999jjDz9IiYnebQsAAADghwg63tCypVSpkhQfb0PYAAAAAOQrgo43BAZKV19t+zNnerctAAAAgB8i6HhLly72SNABAAAA8h1Bx1s6dLCenXXrpH//9XZrAAAAAL9C0PGWcuVsLR2JXh0AAAAgnxF0vInhawAAAECBIOh4kzvozJ8vHT3q1aYAAAAA/oSg403160u1akknT0pz53q7NQAAAIDfIOh4k8vF8DUAAACgABB0vM0ddGbNkhzHu20BAAAA/ARBx9suu0wqVUr67z9p1SpvtwYAAADwCwQdbytVSrrySttn+BoAAACQLwg6RQHzdAAAAIB8RdApCq6+2h6XLJH27/duWwAAAAA/QNApCmrWlBo1klJSpNmzvd0aAAAAwOcRdIoKhq8BAAAA+YagU1S4g87s2VJSknfbAgAAAPg4gk5RcdFFUoUK0sGDNlcHAAAAQJ4RdIqKwECpUyfbZ/gaAAAAcEYIOkUJ83QAAACAfEHQKUo6dZICAqTVq6Xt273dGgAAAMBnEXSKkgoVpKgo2581y7ttAQAAAHwYQaeocQ9fmzJFchzvtgUAAADwUQSdoqZ7dykoSJo/X/rqK2+3BgAAAPBJBJ2ipk4dadgw2x8wQIqL8257AAAAAB9E0CmKhg6V6taVdu+WnnzS260BAAAAfA5BpygKCZHGj7f9d9+Vli71bnsAAAAAH0PQKaquuEK6/XYrSHD//VJSkrdbBAAAAPgMgk5R9uqrUvny0sqV0jffeLs1AAAAgM8g6BRlVapYb44kffmld9sCAAAA+BCCTlF38832OGuWdPSod9sCAAAA+AiCTlHXtKmVnD5+XJo509utAQAAAHwCQaeoc7k8vTpTp3q3LQAAAICPIOj4AnfQmTmT4WsAAABADhB0fEGzZlLt2jZ8bdYsb7cGAAAAKPIIOr6A4WsAAABArhB0fEXa4WvHjnm3LQAAAEARR9DxFc2bS7VqWchh+BoAAACQLYKOr0g7fG3SJO+2BQAAACjiCDq+pGdPe5w2TfroI++2BQAAACjCCDq+pEkTafhw27//fmnBAq82BwAAACiqCDq+5plnbAhbYqJ0443S5s3ebhEAAABQ5BB0fE1AgPTxx1KLFtKBA9I110jx8d5uFQAAAFCkEHR8UenS0owZUvXq0rp10nvvebtFAAAAQJFC0PFVERHSk0/aPouIAgAAAOkQdHzZjTda2ek//pC2bfN2awAAAIAig6Djy8LDpUsusf2vv/ZuWwAAAIAihKDj69yLiDJ8DQAAAEhF0PF1N9xgw9eWLJF27PB2awAAAIAigaDj6yIipLZtbf+bb7zbFgAAAKCIIOj4A4avAQAAAOkQdPzBjTfa42+/STt3erctAAAAQBFA0PEHNWpIbdrY/rRp3m0LAAAAUAQQdPzFTTfZ46RJkuN4ty0AAACAlxF0/MXNN0slS0rR0dJLL3m7NQAAAIBXEXT8RY0a0tixtv/UUwxhAwAAQLFG0PEn994r9e9v+7fdJq1c6dXmAAAAAN5C0PE3r70mXXWVdOyYdO21Umyst1sEAAAAFDqCjr8pUUKaMkU67zxpxw7pmmuko0e93SoAAACgUBF0/FH58tL330sVK0p//indcouUlOTtVgEAAACFhqDjr+rWtbATEiLNmiU9+CBlpwEAAFBsEHT82UUXSZMnSwEB0oQJ0gsveLtFAAAAQKEg6Pi7666T3n7b9p9+WhozxqvNAQAAAAoDQac4ePBBacQI2x80SHr3Xe+2BwAAAChgBJ3iYsQIaehQ2+/XT/rf/7zbHgAAAKAAlfB2A1BIXC7ppZekkyelN96Q7rtP+vxzqVkz29q3l8LDvd1KAAAAIF8QdIoTl8sWFE1Olt56S5o/3zZJqlRJ+usvKSLCmy0EAAAA8gVD14obl0t6801pzRrpo4+khx+WataU9u2TXnnF260DAAAA8oXLcYr+4irx8fEKCwtTXFycQkNDvd0c/zNnjnTVVVJwsLR5s1S9urdbBAAAAGQqp9mAHh1IV14pXXyxzd+hVwcAAAB+gKADG872zDO2//770s6dXm0OAAAAcKbyFHTGjh2rWrVqKSQkRK1bt9bSpUtzdN/kyZPlcrl0/fXX5+VtUZCuuEJq1856dUaO9HZrAAAAgDOS66AzZcoUDR48WCNGjNDy5cvVuHFjdezYUXv27Mn2vq1bt+rRRx9Vu3bt8txYFCCXS3r2WdufMEH67z/vtgcAAAA4A7kOOq+//rruvfde9enTRxdccIHGjx+v0qVL68MPP8zynuTkZPXq1UvPPvus6tSpc9r3OHnypOLj49NtKASXXSZdcomUkCC1aiU98YS0aZO3WwUAAADkWq6CTkJCgpYtW6b27dt7XiAgQO3bt1d0dHSW9z333HOqUqWK7r777hy9z8iRIxUWFpa6RUZG5qaZyCt36enwcGn3bhvCVreuLSh6/fXSAw9Izz8v7drl7ZYCAAAA2crVgqH79u1TcnKywsPD0x0PDw/XunXrMr1n0aJF+uCDD7Ry5cocv8+wYcM0ePDg1Ofx8fGEncLSpIm0fbv03XfS//4n/fijtGKFbW6ffCKtXCmddZa3WgkAAABkK1dBJ7cOHz6s22+/XRMmTFClSpVyfF9wcLCCg4MLsGXIVlCQ1K2bbf/9J/35pxQbK8XEWFW2TZukYcOkt97ydksBAACATOUq6FSqVEmBgYGKjY1Ndzw2NlZVq1bNcP3mzZu1detWde3aNfVYSkqKvXGJElq/fr3OOeecvLQbhaVGDdvcoqKkjh2lt9+24WxXXOG1pgEAAABZydUcnaCgIDVv3lxz585NPZaSkqK5c+cqKioqw/X16tXT6tWrtXLlytTt2muv1eWXX66VK1cyHM0Xdehgc3UkqU8fiUIRAAAAKIJyPXRt8ODBuuOOO9SiRQu1atVKY8aM0dGjR9WnTx9JUu/evVW9enWNHDlSISEhatCgQbr7y5UrJ0kZjsOHjB5tc3e2bJEGD7a5PAAAAEARkuug0717d+3du1dPP/20YmJi1KRJE82ePTu1QMH27dsVEJCndUjhK8qUkT76SLr8cumDD2yh0Tvu8HarAAAAgFQux3EcbzfidOLj4xUWFqa4uDiFhoZ6uzlwe/JJ6aWXpMBAq9LWubO3WwQAAAA/l9NsQNcL8u7556XbbpOSk6WbbpL++MPbLQIAAAAkEXRwJgICbOhahw7SsWNSly7SwoXSiRPebhkAAACKOYIOzkxQkPTVV1KzZtLevdIll9gcngsukB58kKpsAAAA8AqCDs5c2bLSzJm2rk6FCjaU7Z9/pHHjbB4PAAAAUMgIOsgfVatK06ZJ+/ZJO3d6Sk6PGyf9/bd32wYAAIBih6CD/OVySRER0t13Ww9PcrKttVP0i/sBAADAjxB0UHBefdXm8Pz0kw1tAwAAAAoJQQcF55xzpIEDbX/wYCkhwavNAQAAQPFB0EHBevJJKTxc2rhRGjRIWrRIiovzdqsAAADg5wg6KFihodKLL9r+u+9K7dpJ5cpJdepIjz4qrVzJ/B0AAADkO4IOCl6fPtLbb0udO0s1atixLVuk116TmjaVGjaUvvjCu20EAACAX3E5TtH/z+nx8fEKCwtTXFycQkNDvd0cnKmDB6UFC6TPPpO++87m7gQESIsXS61be7t1AAAAKMJymg3o0UHhK1/eSk9/9ZUUGyvddJOUkiLdcw8FCwAAAJAvCDrwrnLlbFHRSpWkNWukl19Ofz45WUpK8krTAAAA4LsIOvC+SpVsDo8kvfCC9PffFm7Gj5eqV5fOPVdavty7bQQAAIBPIeigaOjeXbrmGikxUerRwwoU9O1rQ9u2bZMuvtiGugEAAAA5QNBB0eBy2RC2smWl1auldeusp2fMGKvWdvy4dPPN0nPPUY4aAAAAp0XQQdFRo4b0v/9JtWtLQ4dKmzZJAwZYZbZBg+yaESOkXr2kkye921YAAAAUaZSXhu/43/9sOFtSknTZZdK0aVbMAAAAAMUG5aXhf+65R5o504a3zZ8vtW0rbd9++vvi4qSHHpLmzSvwJgIAAKBoIOjAt3ToIC1cKEVESGvXSlFR0r//Zn/PyJHS2LGe4W8AAADwewQd+J7GjaUlS6QLLpB27ZKuukravTvza+PirMiBJK1aZc8BAADg9wg68E2RkdKcOVKdOtaj07GjdPBgxuvee0+Kj7d9x5Giowu3nQAAAPAKgg58V7Vq0s8/S1WrWknqa66Rjh71nD9xQnrjDduvXNkef/ut8NsJAACAQkfQgW+rU0f66ServrZ4sdSpk7R/v5379FMpJsbKVo8YYccWLfJaUwEAAFB4CDrwfQ0bSrNmSaGhFmTatJE2bpRGjbLzjzwiXXGF7f/+u5SQ4L22AgAAoFAQdOAfoqJsWFpkpLRhg9SokS04WqGClaWuV0+qWFE6flxascLbrQUAAEABI+jAfzRoYNXYmjWz+TmSrZ9Tpozkctm6OxLD1wAAAIoBgg78S0SEtGCBdNttUrt20oABnnMXX2yPFCQAAADwewQd+J8yZawQwa+/2tA1t7Q9Oo5j+3Fx0p13Sp98UujNBAAAQMEh6KD4aN5cCg6W9u61YgWS1L+/NHGi9MADdhwAAAB+gaCD4iM4WGrVyvYXLZKmT/f05Bw/Lo0Z462WAQAAIJ8RdFC8uOfpTJ8u3X+/7bdpY4/vvGND2QAAAODzCDooXtxB57vvpD17pAsvlObMkS64QIqPl95917vtAwAAQL4g6KB4iYqyUtOSVKKEDV0rVUoaNsyOvfGGdOyY99oHAACAfEHQQfFSvrzUpIntDx9ua+5I0q23SrVqWUGC//3PW60DAABAPinh7QYAhe6TT6Tff5fuuMNzrEQJacgQqW9fafRoG9JWsaJUqZJUvbqnFwgAAAA+weU47gVFiq74+HiFhYUpLi5OoaGh3m4O/NWJE1KdOtLu3emPR0VJ33+ffk0eya4LDJSqVCm8NgIAABRzOc0GDF0D3EJCbNjaZZdZj054uAWZ6Gjpyiul/fvtOseRXntNioyUWrSw0tQAAAAoUgg6QFpXXy3NmyetWSPFxEirVlngWbnSws7mzVK3btKjj0rJydKOHdLXX3u71QAAADgFQQfIzgUXWPAJD5f++kuqW1eaNk0KCrKeH0l6/32vNhEAAAAZEXSA06lfX5o/X6pWzYat1awpLVokffaZFBAgLVworVvn7VYCAAAgDYIOkBP16tlcnbfekpYvl1q2tGpsXbrY+QkTvNs+AAAApEPQAXLq7LOlhx+2stNu991njxMnSidPeqddAAAAyICgA5yJTp2kGjWsItu0aWf+evPm2To/Rb/qOwAAQJFG0AHORIkS0l132X52w9f2788+vBw9Kj3wgHTFFbaQ6fff5287AQAAihmCDnCm7r5bcrmkX36xymxp/fmn1L69VKmS9Nxzmd//xx9S06bSe+95jn34YcG1FwAAoBgg6ABnqmZNqXNn22/SRGrVSnrxRal7dytaMHeunXvpJWnLlvT3/vST1KaNtHGjFTcYO9aOf/+9tGdPoX0EAAAAf0PQAfLDm29aYJGsh+app6Qvv7Sent69pXbtpIQE6YknPPccPCj16SMlJUnXXWeLkz74oIWjpCTp88+981kAAAD8AEEHyA/nniv99pu0e7ctIHrttVKPHtLKlVaR7a23LPRMniz9/rvdM2iQtGuXLUI6aZJUoYIdd8/5+egjihIAAADkkctxiv5fUvHx8QoLC1NcXJxCQ0O93Rwgb/r0kT7+WLr4YmnIEKlrVws/CxdKbdt6rjt0yBYnPXHCeodatPBWiwEAAIqcnGYDenSAwvL881KpUtKiRTZ/R5IGD04fciSpXDnphhts/6OPCrWJAAAA/oKgAxSWGjWkRx6x/WPHpPPPt/CTmT597HHSJOvZAQAAQK4QdIDC9PjjUkSErb/z0UfWw5OZK66QIiNtGNuMGYXaRAAAAH9A0AEKU9myNu9m9WopKirr6wIDpTvvtP1XXpGOHy+U5gEAAPgLgg5Q2CIipHr1Tn/d/fdbJbYVK6R776UCGwAAQC4QdICiqnp16auvrHfn88+lUaO83SIAAACfQdABirLLL7c1eCRp2DDpu+9ydt/Bg1bwAAAAoJgi6ABF3YMPSg88YEPXevWSvv4662sdRxo7VqpaVWrSxAIPAABAMUTQAXzBW29ZJbbDh6WbbpJuuUXasyf9NfHx0q23Sg89JCUkSBs3SnfcwdweAABQLBF0AF9QsqQ0a5b05JM2Z2fqVOnCC6V+/aRBg6xsdYsW0pdfWunqRx+VgoJsqNtrr3m79QAAAIXO5ThF/z/3xsfHKywsTHFxcQoNDfV2cwDvWrbMFhRdvTrjuchICzsXXSSNHy/17WvBaMECqW3bwm8rAABAPstpNiDoAL4oIUH65BNp+3YpMdG2sDCbz1Oxol3jONJtt0mTJlkFtxUrpMqVvdtuAACAM0TQASAdOSK1bCmtWyfdc480YYK3WwQAAHBGcpoNmKMD+LMyZaQPPrD9jz6SNmzwbnsAAAAKCUEH8Hdt2kjXXCMlJ0vDh3u7NQAAAIWCoAMUBy++KLlcVqhg+XJvtwYAAKDAEXSA4qBRI6lnT9t/4onMr0lIkO68U+rSRVqzptCaBgAAUBAIOkBx8eyztsbOjz9auem0UlKk3r2liRNtvZ6mTW3NnuPHvdNWAACAM0TQAYqLc86R7r3X9h9+WFq1yvYdRxowQJoyxRYmvfJKKSlJeukl6wlassR7bQYAAMgjgg5QnAwfbuvtrF4tNWliw9kee0x65x07P3GiNGeO9M03UkSEtGmTdOml0qeferXZAAAAuUXQAYqTatWkpUulW26xnpwvvpBee83Ovfmm1KOH7d9wg7R2rXT99TZ3p3dvadgwG+IGAADgAwg6QHFz3nk2TG35cis84HJJI0ZI/funvy4sTPr6a0/xgpdfljp3tt6eI0cKv90AAAC5kKegM3bsWNWqVUshISFq3bq1li5dmuW1EyZMULt27VS+fHmVL19e7du3z/Z6AIWkaVPp+++lY8ekZ57J/JqAACtN/emnUnCw9NNPUrduUsWKFnqYvwMAAIqoXAedKVOmaPDgwRoxYoSWL1+uxo0bq2PHjtqzZ0+m18+fP189evTQvHnzFB0drcjISHXo0EE7d+4848YDyAchIae/5rbbpD/+kAYNsqIGCQnS7NnSVVdJK1YUfBsBAAByyeU4jpObG1q3bq2WLVvqnf+fvJySkqLIyEg9/PDDGjp06GnvT05OVvny5fXOO++od+/eOXrP+Ph4hYWFKS4uTqGhoblpLoD85jjSunVSv37SvHlSeLgUHS3Vrp2z+w8flkqVslLXAAAAuZTTbJCrHp2EhAQtW7ZM7du397xAQIDat2+v6OjoHL3GsWPHlJiYqAoVKmR5zcmTJxUfH59uA1BEuFxS/frStGlWfjo2VurYUdq3L/Pr9+yRvvrKSlo3aiSFhlolt5MnC7fdAACgWMnVf1Ldt2+fkpOTFR4enu54eHi41q1bl6PXGDJkiCIiItKFpVONHDlSzz77bG6aBqCwhYVJP/wgtWkjbdwoXX651L69VLmyVL68lbBesMCqt51q8WJpyBBpzJj0xx3HKrsFBhbKRwAAAP6rUMeOvPzyy5o8ebLmz5+vkGzmBQwbNkyDBw9OfR4fH6/IyMjCaCKA3IiIsLk6bdtKa9bYlpmGDa0Xx92Tc9ttVs76ssushLVkr3P33VYVbu5cK4QAAACQR7kKOpUqVVJgYKBiY2PTHY+NjVXVqlWzvffVV1/Vyy+/rDlz5qhRo0bZXhscHKzg4ODcNA2At9SrJ/35p5Wi3rNH2rtX2r/f5uxcdpnUrp1UqVL6e1assPV7+vSx4Wwffyy98IL16OzaJX37rScAAQAA5EGeihG0atVKb7/9tiQrRlCzZk099NBDWRYjGDVqlF588UX9+OOPuuiii3LdSIoRAH4mIcEC0NKlUunSVuJast6cDRukqCgb3gYAAHCKAilGIEmDBw/WhAkTNHHiRP3zzz/q27evjh49qj59+kiSevfurWHDhqVe/8orr2j48OH68MMPVatWLcXExCgmJkZHWHAQKL6CgmzR0rAwCzmlS9taPQsW2LnoaOm337zdSgAA4MNyHXS6d++uV199VU8//bSaNGmilStXavbs2akFCrZv367du3enXj9u3DglJCTopptuUrVq1VK3V199Nf8+BQDfU6uW9N13Nnzt999t3k7VqpK77PyoUV5tHgAA8G25HrrmDQxdA4qR9eutfLXjWMW2+vW93SIAAFCEFNjQNQAoUOefL117re2/9pp32wIAAHwWQQdA0fP44/b46adWavrgQe+2BwAA+ByCDoCip00b2xISbBHSChWkatWk7t2lVau83ToAAOADCDoAiqaxY6XOnSX3YsExMdKXX0qNG0u33GLzdwAAALJA0AFQNDVpIs2aJW3fLsXHW7np7t3t3NSpUoMG0hNPSCkp6e/buFEaMEBauLDQmwwAAIoOgg6Aoq9sWRvKNnmyDV278UaryjZypO271+X69FOpWTPprbekK66Q3nvPu+0GAABeQ9AB4FsaNpS+/lr65BNbXHTGDKltW1uHp3dvCz3Vq0tJSdIDD0j9+9s+AAAoVgg6AHzT7bdLCxZI4eHWy/P551JAgPTcc9LWrdKLL9p1b78tNW0qXX659Qq1bm09PwAAwK+xYCgA37Zjh3TrrdLevdIHH0jt2nnOTZtmPT3HjqW/JyhIWrbM5vkAAACfktNsQNAB4B8cR3K5Mh7fulVatEgqWVIKDpbGjZN++sl6eZYssdDj9t9/UuXKdh0AACiScpoNGLoGwD9kFnIkqVYt69Xp3l26/npp4kSpYkVpxQrp+eftmoQEacgQK2XdoIFVbstOcrIUG5ufrQcAAPmMoAOgeKla1Xp1JOmll6QvvpAuvlgaNcqObdokRUVZOetT/fuvNHy4hae0rwMAAIochq4BKJ569ZImTfI8L19eeu016d13pT//tOFrY8bYkLe//rJj0dHpXyMoyAJRixaF2nQAAIoz5ugAQHYOHrRS1Tt3WgGDzz6TataUjh61EDRjRsZ7XC7pqquku++2nqDp06XataXly6Vy5Qr7E5y5pCT7TIGB3m4JAAA5RtABgNPZvt16aq69VipRwnM8OdmGqH35pQ1Ta9zYtksvlc4+2645eNAWJ926VerWTZo6Net5QkXRiRP2mcqUkf74w0pzAwDgAwg6AFDQli61+T2JiVLfvlL9+jbUrVQpK2rQsGH6qm5FyZIlNhdJsnlJ55zj3fYAAJBDOc0GJbI8AwDIXqtW0ujR0sCBmRcmCAqyXpMuXayqW0hIoTcxS3/+6dlfuZKgAwDwOwQdADgT/ftbL85vv9mcl8REKS7OwsOBAzYs7I8/pK+/lj7/3Hp5JFvgdOJEu7d//8If9rZsmWf/r79s+B0AAH6EoAMAZ8Llkh580La0HEfaskVasEAaOlRavdqqsz35pLRhg83pSUiwa+vWla6+unDbfWqPDgAAfoY5OgBQ0GJjrVLbzJnpj1eqJO3bJ11yiQWiwnL0qBQaKqWk2PPISCvMAACAD8hpNqDMDgAUtPBw6bvvbB7POedIffpYIYOVK23o2q+/WnGAwrJypYWc8uXt+Y4dNswOAAA/QtABgMLgckkPPGAVzj78UGrZUqpeXbrtNjv/yiuF1xb3/JyLL5bq1LH9v/4qvPcHAKAQEHQAwJsee8weZ8yQ1q0rnPd0z89p0cKqwknM0wEA+B2CDgB4U/36tmCp40ivvlo475k26DRpYvsEHQCAnyHoAIC3DRlij59+Ku3alb+vfeKElJzseX74sKfnqHlzgg4AwG9RXhoAvK1NG5svs2iR1Lq1BZCGDa0y2po1Vpp6yxbpxhuld9+VgoNz9rpr1kiXXy6de669dmCgBRrHkWrUsCIJ7qCzdq108mTOXxsAgCKOoAMARcEzz0gdO0r//WfbjBkZr/nwQ2nbNmnaNKls2exfb+9eqWtXK1+9b58tTnrXXemHrUlWWrp8eengQemffzzBBwAAH0fQAYCi4MorpT17rPrZ6tXWGxMfL114ofXuJCZaWeq5c62XZtYsqUqVzF/r5Enr/dm6VQoJseFrw4dLt96aMei4XFaQYP586+0h6AAA/ARBBwCKigoVLMRcfnnm52vXljp3tvLQjRtLdetKQUE23Ozcc6W2bW176ikbqhYWZgHm+uutJ2jMGE/Qad7c87pNmniCDgAAfoKgAwC+okUL6bffpA4dLLjExKQ//9Zbnv3AQOnLLy3EvPiirdczcqR05IidPzXoSAQdAIBfIegAgC857zxp1Srp119tSFpCgnTsmA15W7TIzqWkWO9Nhw52T48e0muvSStW2POzz5YqV/a8pjvo/PWXFSpwubJvw6FDttWqla8fDQCA/ETQAQBfExoqXXNN5ufi4634QJ06nmMBAdLo0VL79vbcPT/HrX59qWRJCy/bt1sQysqWLVK7dtLOndaGJ5+ULrrojD4OAAAFgXV0AMCfhIamDzluV15p83skK2WdVlCQdMEFtu/u9clMTIx01VUWciTp+++lqCgLUH//feZtBwAgHxF0AKC4mDxZ+uwzqW/fjOfcw9duuslCzy23SK++Km3caMcPHZI6dZI2b7YhawsWWLnqEiWsElznzlaiGgCAIsLlOI7j7UacTnx8vMLCwhQXF6fQ0FBvNwcA/M+8eRZu9u3LeO7CC624wapVtsjookVW5U2yoghXXWWBqFs3aerU08/xAQDgDOQ0GxB0AADGcWxY2po1Fmp+/tnKTicl2fmwMCuC0KhR+vuWLbMhbImJ0vvvS/feW+hNBwAUHwQdAMCZO3hQmjnTenHuvTd9Weq0Ro+WHn9cKlXKgk/9+hmv+e036Y8/bOHTsLDs33ffPql0adsAAEgjp9mAOToAgKyVL29r8Iwfn3XIkaRHHrGiBMeP2xC4b7+Vjh61c2vXStdea0UQBg2yEPTVV9aDlJlFi6zy2/nnSzt25P9nAgAUC/ToAADyx+7dNqzNPc8nOFhq1kz6/Xdb2ycwUKpa1VO17ZprpHfeSV/Oeu1aC0TuwgaNG0sLF0plyxbuZwEAFFn06AAACle1ahZK+vWzymwnT0rR0RZybrzRSlBv2iQNH27r9nz/vfXuPPusLXq6a5enelurVlb44K+/bMHT5GRvfzoAgI+hRwcAkP8cR1q3zoahNW5swSWtf/6xMtcLFtjzmjWls86y4+efb/N5Nm+WLr1UOnFC6t9fevPNwv8cAIAih2IEAICizXGsHPWjj3rm4oSHWy9Q7dr2/KuvpJtvtv1ataSLLrKtUycLRACAYoegAwDwDceOWdW2+fOl11+XmjZNf/7NNy0MuctcS1JAgA2Re+45qVy5wmwtAMDLCDoAAP8RH2+lqZcssUA0Z44dDw+XXn5ZatnSwo/LJVWoIFWpkvE1EhNtONzatbZt3Sp16GA9RixyCgA+g6ADAPBfc+ZIDz0krV+f+fkqVWxuUL16UkyMBZsNGyzsnOrqq6Vx42yeEACgyCPoAAD8W0KCDXUbP97W7ElJsS0uLus1es46S7rgAtvKlJEmTLDXKVNGeukl6cEHrQx2dpKTpdWrrcLcwoU2v+idd7JfZwgAkG8IOgCA4unYMWnNGitNvX69FBHhCTc1atgQN7d//pHuvdeqvEnWC/TWW9Ill2T+2uvWWQnsrVvTH69eXfrzT1snCABQoAg6AADkREqK9N570hNPSIcO2bHu3a1AQmSk57otW6R27WzB0zJlpDZt7Pnnn1sAatNG+uUXWygVAFBgWDAUAICcCAiwNX02bpTuv98KE0yZYuWrn39eOn7cFjNt395CzgUXWOj58UfpqaekGTOksDBp8WLp4YezHjYHAChU9OgAAJDWihW2QOmiRfa8Vi3rpVm/XqpTx+blRESkv2f2bCtq4Dg2FK5SJQtIJUtK990nnXtuoX8MAPBXDF0DACCvHEeaPFl67DHrxZEs3Cxa5FnM9FSvvCINHZrxeJky0rvvSrffXnDtBYBihKADAMCZOnrUAszSpdIbb0j162d9reNI//uftGyZFBIilSplRQ4WLrTzvXpZ4Mnt/x87ftxeu3TpvH8OAPAjBB0AALwtOVkaOVJ65hnbL1vWylA3b24V3kJCpKQk21wuCzOlStm8od9/t+IG0dEWdPr3l4YPt/lAAFCMEXQAACgqFi+WbrvNihicicqVpRdflK64wnp6jh+XypdnDhCAYoWgAwBAUZKUJK1da0Pbli2T/v7bemoCA6USJazM9fHjtg7QyZNSgwYWaK64Qtq0SRo0yAoiZObee6XXXrMeIwDwcwQdAAD8SWKiNHasNGqUdPiwDXErVUrascMCU+3a0scfZ73YKQD4CdbRAQDAn5QsKQ0caGv6HD4s7dkjbdsmzZtnJbC3bJEuu8x6d7Lq+QGAYoQeHQAAfN3hw9LgwVb1ze2aa6S77pISEqSYGNuqV7fjtWp5rakAcKYYugYAQHGzaJE0erT03Xc2nC0rDRpIXbpIV10ltWljQ+Byw3FszlFioi2mGhh4Zu0GgFwg6AAAUFxt2GDr/ixcKFWoIFWrZhXbVq+2tX2Skz3XBgVJUVFSeLi0e7cNjduzx8pdBwZ6Qkxiom0JCRZy3CpUkB591Mpfn3VW4X5OAMUSQQcAAGR04ID044/SrFk2v2fnzvx53SpVpKFDpVatLEilpFhP0XnnWQlsAMgnBB0AAJA9x7HS1fPnS0ePShERtlWpYouWJid7em9KlrTen5IlPVuJEtKMGbYg6ubNWb9PlSpSvXpSp07SPfdY7xIA5BFBBwAAFI7ERCttPW6cFUZwD3mLi8vYYxQUJN1yi3T77VJoqAWqgABb9LRcucJpr+NYiCtRonDeD0C+IugAAADvO3zY5gwtX25V4ZYuzfy6EiWkK6+UunWTrrvOeoEKwg8/2JyiXbukF16QHniAYgqAjyHoAACAoufPP23h00WLPHN5EhKsEEJa1apJ559v23nnefZr1JC2b5c2brTt4EHP65z6WKaM9RTVrWtD7Z5+2uYnpdWypTR+vFS1qrVp0SJp3Trp2DEbznfihNSsmXT//VK7dlakAYBXEXQAAIDvWL9e+vpr25YvL7j3KVlSGjBAioyUhg+X4uNzfm/9+tYDdP/9VlYbgFcQdAAAgG86dMiGu61f79k2bLDtxAmpdGnrpalb14a4BQbaPJ9THw8c8PT8xMTYYqmjRlkvj2S9SIMHS5MnW09N48bWa9Osmc0fcpfL/vpradIk6+GRpAsvtDlJLVp449sBij2CDgAA8C8pKTZUrUKF3A8hc5ys79m504a5hYVlfX98vPTZZ9Kzz9o6Q4GB0mOPST17Sv/9Z8Pp4uKkiy6yLSgod+3DmYmOlo4fly6/nOGFxQBBBwAAIL/t22eLo37xRdbXlC4tXXqp1LSpVKmSVLGihbOgICu6cOrmONbjtGOHhabjx60CXViYrUF0wQVSw4a+G57GjbMS5lddJXXtaovT5qdFi+z7TkmRmje3uVhduxJ4/BhBBwAAoKBMn27D3g4dkmrWtC0oSPr1V2nv3vx/v+BgC06NG1tBBveaR9Wr26O7l+vAAVvTaMsWG75XoYJtFStagYe8ltROSLAgVrq0vU5OOI71gD37rOeYyyW1bm3V9bp3t7lSZyIuzr6TbdvSH2/SROrRQ7riCvveqKznVwg6AAAAhS0lRVqzRpo718LGvn22HTxo6w0lJaXf3BXiwsMtwERG2tyguDgLUXv3SitW2H52goKkkJDsiysEBFgoioyU6tSxOU7nnSfVrm1BqkQJCwS7dtlnWLNGWrtW2rrVepzcfzLWq2e9M+3bW6CoUcNeOy3HkZ54Qnr5ZXt+22021+qPP9Jf166ddMMNFtjcoey882woYU706mXzp+rUkX7+WZowQXrnHenIEc81YWHWw/PKK/b54fMIOgAAAP7AcayX5vffrfT17t02r2jXLtv27Ut/fbVq9oe/y2UB68ABC0xJSWfWjpAQ69lJSUl/vFQpCyfnnmshKjLS2jlhgp1/4w1p4EDb37lT+vZbKwDx66+Zv0+JEjbPqX17m3Nz4YXWI3Wqzz+3ABUYKC1cKEVF2fH9+6VPP5V++UVasMAT/sLCpNdfl/r0YVibjyPoAAAAFAcnT1r4OXZMqlXLhpedKiVFio214Wfbt1tw2rDBKtJt3269TcnJFoYqVLA5QQ0a2PygOnWks8+WKle2nqV586Q5cyxEbNxo92bl3Xelvn0zP7djhzRlirR4sYWx/fut0MOePRmvrVDB1lFy9/yUK2frH8XH29C4p5/O/D2SkqQlS6RBg2wNJ8kC1C232PypSpVsHlTp0hbYQkLs+zxyxLbERKvAFxpqQalUqcxDUlKS9Wqd2rN1qj177LuvUcO2/ApcJ05Yr1wxCXAFGnTGjh2r0aNHKyYmRo0bN9bbb7+tVq1aZXn91KlTNXz4cG3dulV169bVK6+8oquvvjrH70fQAQAAKIKSkmxo2/r10r//WnjZscOCy913W6DIrX//taF/c+daCNqxI+tr27a1Qgenm3uUlGQ9S08/baEgrwIDPaEnONiCVlychcyAAAtgFSpYeHI/li9vQfTPP63YhNtZZ1lPWM2a9pply9oWGGiBxeWyAFalim2VK1vb3cMat2+XVq607d9/7f1atpRatbJ5S1WqeOZnBQRYgEtIsB7CSpXsM2QXjJKT7fzpwpsXFFjQmTJlinr37q3x48erdevWGjNmjKZOnar169erSpUqGa5fvHixLrnkEo0cOVLXXHONJk2apFdeeUXLly9XgwYN8vXDAAAAwM8cPSpt2mRhKjbWhuMdPGjhZdiw3M272bBBGjPGAod7/tShQ1bp7tgxz7C8MmU8oePwYQs0+TEIyuWy9sbEWJDwppIlLQyVKWOf0x0WDx2y7/fwYQs55ctbWKpUycqp9+vn1WZLBRh0WrdurZYtW+qdd96RJKWkpCgyMlIPP/ywhg4dmuH67t276+jRo/r+++9Tj1100UVq0qSJxo8fn68fBgAAAMgTx7GhaiVKZF5c4ehR602Jj7ftxAnriSlXzh4TE60nyz0vKu1juXJW+rpJE7s2IcF6Ydzhzf2ahw9bAHL/eX7kiGc43759NrTOXXo8PNx6bpo0sXlMO3ZIS5fatm6dZzjgwYP2ekFBtrk/S1488YT04ot5/orzS06zQa5qDCYkJGjZsmUaNmxY6rGAgAC1b99e0dHRmd4THR2twYMHpzvWsWNHTZ8+Pcv3OXnypE6ePJn6PD67CiIAAADAmXK5sl6ryOWyno8yZWyeUFaqVs3ZewUFWfW6evVy386shIdLLVpIDz6Y/nhKimconNvx41agYs8e23dXAXQcz/pN5crZvfv2WWDav98KTviQXAWdffv2KTk5WeGnLPQUHh6udevWZXpPTExMptfHxMRk+T4jR47Us2lrrgMAAADIvczm2JQq5Vn/6XRyGt6KoKI3u0jSsGHDFBcXl7rtyG4SGgAAAACcIlc9OpUqVVJgYKBiY2PTHY+NjVXVLNJe1apVc3W9JAUHBys4ODg3TQMAAACAVLnq0QkKClLz5s01d+7c1GMpKSmaO3euotyLNJ0iKioq3fWS9PPPP2d5PQAAAACcqVz16EjS4MGDdccdd6hFixZq1aqVxowZo6NHj6pPnz6SpN69e6t69eoaOXKkJGnAgAG69NJL9dprr6lLly6aPHmy/vzzT73//vv5+0kAAAAA4P/lOuh0795de/fu1dNPP62YmBg1adJEs2fPTi04sH37dgWkmfTUpk0bTZo0SU899ZSeeOIJ1a1bV9OnT8/xGjoAAAAAkFu5XkfHG1hHBwAAAICU82xQJKuuAQAAAMCZIOgAAAAA8DsEHQAAAAB+h6ADAAAAwO8QdAAAAAD4HYIOAAAAAL9D0AEAAADgdwg6AAAAAPwOQQcAAACA3yHoAAAAAPA7BB0AAAAAfqeEtxuQE47jSJLi4+O93BIAAAAA3uTOBO6MkBWfCDqHDx+WJEVGRnq5JQAAAACKgsOHDyssLCzL8y7ndFGoCEhJSdGuXbtUtmxZuVwur7YlPj5ekZGR2rFjh0JDQ73aFn/E91vw+I4LFt9vweM7Lnh8xwWL77fg8R0XLG9/v47j6PDhw4qIiFBAQNYzcXyiRycgIEA1atTwdjPSCQ0N5f9wChDfb8HjOy5YfL8Fj++44PEdFyy+34LHd1ywvPn9ZteT40YxAgAAAAB+h6ADAAAAwO8QdHIpODhYI0aMUHBwsLeb4pf4fgse33HB4vsteHzHBY/vuGDx/RY8vuOC5Svfr08UIwAAAACA3KBHBwAAAIDfIegAAAAA8DsEHQAAAAB+h6ADAAAAwO8QdAAAAAD4HYJOLowdO1a1atVSSEiIWrduraVLl3q7ST5r5MiRatmypcqWLasqVaro+uuv1/r169Ndc9lll8nlcqXbHnjgAS+12Lc888wzGb67evXqpZ4/ceKE+vXrp4oVK6pMmTLq1q2bYmNjvdhi31OrVq0M37HL5VK/fv0k8fvNrV9//VVdu3ZVRESEXC6Xpk+fnu684zh6+umnVa1aNZUqVUrt27fXxo0b011z4MAB9erVS6GhoSpXrpzuvvtuHTlypBA/RdGW3XecmJioIUOGqGHDhjrrrLMUERGh3r17a9euXeleI7Pf/csvv1zIn6RoOt1v+M4778zw3XXq1CndNfyGs3e67zizf5NdLpdGjx6deg2/4azl5G+znPz9sH37dnXp0kWlS5dWlSpV9NhjjykpKakwP0oqgk4OTZkyRYMHD9aIESO0fPlyNW7cWB07dtSePXu83TSftGDBAvXr109LlizRzz//rMTERHXo0EFHjx5Nd929996r3bt3p26jRo3yUot9z4UXXpjuu1u0aFHquUGDBum7777T1KlTtWDBAu3atUs33nijF1vre/7444903+/PP/8sSbr55ptTr+H3m3NHjx5V48aNNXbs2EzPjxo1Sm+99ZbGjx+v33//XWeddZY6duyoEydOpF7Tq1cv/f333/r555/1/fff69dff9V9991XWB+hyMvuOz527JiWL1+u4cOHa/ny5frmm2+0fv16XXvttRmufe6559L9rh9++OHCaH6Rd7rfsCR16tQp3Xf3xRdfpDvPbzh7p/uO0363u3fv1ocffiiXy6Vu3bqlu47fcOZy8rfZ6f5+SE5OVpcuXZSQkKDFixdr4sSJ+vjjj/X000974yNJDnKkVatWTr9+/VKfJycnOxEREc7IkSO92Cr/sWfPHkeSs2DBgtRjl156qTNgwADvNcqHjRgxwmncuHGm5w4dOuSULFnSmTp1auqxf/75x5HkREdHF1IL/c+AAQOcc845x0lJSXEch9/vmZDkTJs2LfV5SkqKU7VqVWf06NGpxw4dOuQEBwc7X3zxheM4jrN27VpHkvPHH3+kXvPDDz84LpfL2blzZ6G13Vec+h1nZunSpY4kZ9u2banHzj77bOeNN94o2Mb5gcy+3zvuuMO57rrrsryH33Du5OQ3fN111zlXXHFFumP8hnPu1L/NcvL3w6xZs5yAgAAnJiYm9Zpx48Y5oaGhzsmTJwv3AziOQ49ODiQkJGjZsmVq37596rGAgAC1b99e0dHRXmyZ/4iLi5MkVahQId3xzz//XJUqVVKDBg00bNgwHTt2zBvN80kbN25URESE6tSpo169emn79u2SpGXLlikxMTHd77levXqqWbMmv+c8SkhI0Geffaa77rpLLpcr9Ti/3/yxZcsWxcTEpPvNhoWFqXXr1qm/2ejoaJUrV04tWrRIvaZ9+/YKCAjQ77//Xuht9gdxcXFyuVwqV65cuuMvv/yyKlasqKZNm2r06NFeG5Lii+bPn68qVaro/PPPV9++fbV///7Uc/yG81dsbKxmzpypu+++O8M5fsM5c+rfZjn5+yE6OloNGzZUeHh46jUdO3ZUfHy8/v7770JsvSlR6O/og/bt26fk5OR0/6NJUnh4uNatW+elVvmPlJQUDRw4UG3btlWDBg1Sj/fs2VNnn322IiIitGrVKg0ZMkTr16/XN99848XW+obWrVvr448/1vnnn6/du3fr2WefVbt27bRmzRrFxMQoKCgowx8v4eHhiomJ8U6Dfdz06dN16NAh3XnnnanH+P3mH/fvMrN/g93nYmJiVKVKlXTnS5QooQoVKvC7zoMTJ05oyJAh6tGjh0JDQ1OP9+/fX82aNVOFChW0ePFiDRs2TLt379brr7/uxdb6hk6dOunGG29U7dq1tXnzZj3xxBPq3LmzoqOjFRgYyG84n02cOFFly5bNMCyb33DOZPa3WU7+foiJicn032r3ucJG0IHX9evXT2vWrEk3h0RSunHJDRs2VLVq1XTllVdq8+bNOueccwq7mT6lc+fOqfuNGjVS69atdfbZZ+vLL79UqVKlvNgy//TBBx+oc+fOioiISD3G7xe+KjExUbfccoscx9G4cePSnRs8eHDqfqNGjRQUFKT7779fI0eOVHBwcGE31afceuutqfsNGzZUo0aNdM4552j+/Pm68sorvdgy//Thhx+qV69eCgkJSXec33DOZPW3ma9h6FoOVKpUSYGBgRmqSsTGxqpq1apeapV/eOihh/T9999r3rx5qlGjRrbXtm7dWpK0adOmwmiaXylXrpzOO+88bdq0SVWrVlVCQoIOHTqU7hp+z3mzbds2zZkzR/fcc0+21/H7zTv37zK7f4OrVq2aoThMUlKSDhw4wO86F9whZ9u2bfr555/T9eZkpnXr1kpKStLWrVsLp4F+pE6dOqpUqVLqvwn8hvPPwoULtX79+tP+uyzxG85MVn+b5eTvh6pVq2b6b7X7XGEj6ORAUFCQmjdvrrlz56YeS0lJ0dy5cxUVFeXFlvkux3H00EMPadq0afrll19Uu3bt096zcuVKSVK1atUKuHX+58iRI9q8ebOqVaum5s2bq2TJkul+z+vXr9f27dv5PefBRx99pCpVqqhLly7ZXsfvN+9q166tqlWrpvvNxsfH6/fff0/9zUZFRenQoUNatmxZ6jW//PKLUlJSUkMmsucOORs3btScOXNUsWLF096zcuVKBQQEZBhyhdP777//tH///tR/E/gN558PPvhAzZs3V+PGjU97Lb9hj9P9bZaTvx+ioqK0evXqdKHd/R9NLrjggsL5IGkVevkDHzV58mQnODjY+fjjj521a9c69913n1OuXLl0VSWQc3379nXCwsKc+fPnO7t3707djh075jiO42zatMl57rnnnD///NPZsmWLM2PGDKdOnTrOJZdc4uWW+4ZHHnnEmT9/vrNlyxbnt99+c9q3b+9UqlTJ2bNnj+M4jvPAAw84NWvWdH755Rfnzz//dKKiopyoqCgvt9r3JCcnOzVr1nSGDBmS7ji/39w7fPiws2LFCmfFihWOJOf11193VqxYkVrx6+WXX3bKlSvnzJgxw1m1apVz3XXXObVr13aOHz+e+hqdOnVymjZt6vz+++/OokWLnLp16zo9evTw1kcqcrL7jhMSEpxrr73WqVGjhrNy5cp0/y67KyUtXrzYeeONN5yVK1c6mzdvdj777DOncuXKTu/evb38yYqG7L7fw4cPO48++qgTHR3tbNmyxZkzZ47TrFkzp27dus6JEydSX4PfcPZO9++E4zhOXFycU7p0aWfcuHEZ7uc3nL3T/W3mOKf/+yEpKclp0KCB06FDB2flypXO7NmzncqVKzvDhg3zxkdyCDq58Pbbbzs1a9Z0goKCnFatWjlLlizxdpN8lqRMt48++shxHMfZvn27c8kllzgVKlRwgoODnXPPPdd57LHHnLi4OO823Ed0797dqVatmhMUFORUr17d6d69u7Np06bU88ePH3cefPBBp3z58k7p0qWdG264wdm9e7cXW+ybfvzxR0eSs379+nTH+f3m3rx58zL9N+GOO+5wHMdKTA8fPtwJDw93goODnSuvvDLD975//36nR48eTpkyZZzQ0FCnT58+zuHDh73waYqm7L7jLVu2ZPnv8rx58xzHcZxly5Y5rVu3dsLCwpyQkBCnfv36zksvvZTuD/XiLLvv99ixY06HDh2cypUrOyVLlnTOPvts5957783wH0v5DWfvdP9OOI7jvPfee06pUqWcQ4cOZbif33D2Tve3mePk7O+HrVu3Op07d3ZKlSrlVKpUyXnkkUecxMTEQv40xuU4jlNAnUUAAAAA4BXM0QEAAADgdwg6AAAAAPwOQQcAAACA3yHoAAAAAPA7BB0AAAAAfoegAwAAAMDvEHQAAAAA+B2CDgAAAAC/Q9ABAAAA4HcIOgAAAAD8DkEHAAAAgN/5PwJwcx2yID+LAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(result['loss'] , c='red' , label='loss')\n",
    "plt.plot(result['accuracy'] , c='blue' , label='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "223b9e25-4924-4127-b7e1-136a994f4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y ,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdaa1a96-59ce-4340-94e2-fed5d95d48d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 2s 5ms/step - loss: 0.7046 - accuracy: 0.5103\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5241\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6840 - accuracy: 0.5310\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5448\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.6000\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.5793\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.7034\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.7172\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.7448\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.6966\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7379\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7655\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7862\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.7655\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7862\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.8069\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7931\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8276\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8138\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8207\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8138\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8414\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.3670 - accuracy: 0.8483\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3636 - accuracy: 0.8690\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.8483\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3547 - accuracy: 0.8414\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8690\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8621\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8345\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8690\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3122 - accuracy: 0.8483\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8759\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2955 - accuracy: 0.9034\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2973 - accuracy: 0.8690\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8966\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2781 - accuracy: 0.8828\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2772 - accuracy: 0.8828\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2663 - accuracy: 0.8966\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2612 - accuracy: 0.8828\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8966\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.8690\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.9103\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9103\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.8759\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2224 - accuracy: 0.9517\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2250 - accuracy: 0.9034\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2216 - accuracy: 0.9241\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2217 - accuracy: 0.9241\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9586\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9241\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2384 - accuracy: 0.8759\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1993 - accuracy: 0.9517\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2084 - accuracy: 0.9034\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9241\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1836 - accuracy: 0.9517\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1817 - accuracy: 0.9655\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9655\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9655\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.9655\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9517\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9655\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9310\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9655\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9586\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1495 - accuracy: 0.9724\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9724\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9448\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9724\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9655\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1299 - accuracy: 0.9655\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9724\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1212 - accuracy: 0.9793\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9724\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9655\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9793\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9793\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9793\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.9862\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9931\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9724\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9862\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9931\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0851 - accuracy: 0.9931\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9931\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9931\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9931\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9793\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9931\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "2/2 [==============================] - 1s 12ms/step - loss: 0.5495 - accuracy: 0.8730\n",
      "Accuracy: 0.8730158805847168\n"
     ]
    }
   ],
   "source": [
    "#모델\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history = model.fit(X_train,y_train, epochs=200, batch_size=5)\n",
    "# result\n",
    "print(f'Accuracy: {model.evaluate(X_test,y_test)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ede4fc66-805f-4dbf-9d92-25c43117c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "29/29 [==============================] - 2s 6ms/step - loss: 0.6970 - accuracy: 0.5793\n",
      "Epoch 2/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.6759\n",
      "Epoch 3/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.7172\n",
      "Epoch 4/120\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.7448\n",
      "Epoch 5/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7517\n",
      "Epoch 6/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7034\n",
      "Epoch 7/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7172\n",
      "Epoch 8/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.7655\n",
      "Epoch 9/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7586\n",
      "Epoch 10/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7862\n",
      "Epoch 11/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7724\n",
      "Epoch 12/120\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7724\n",
      "Epoch 13/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7655\n",
      "Epoch 14/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7931\n",
      "Epoch 15/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4895 - accuracy: 0.7724\n",
      "Epoch 16/120\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4609 - accuracy: 0.8000\n",
      "Epoch 17/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.8207\n",
      "Epoch 18/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8069\n",
      "Epoch 19/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.8069\n",
      "Epoch 20/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.8483\n",
      "Epoch 21/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8207\n",
      "Epoch 22/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8483\n",
      "Epoch 23/120\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4048 - accuracy: 0.8207\n",
      "Epoch 24/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8483\n",
      "Epoch 25/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8414\n",
      "Epoch 26/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8621\n",
      "Epoch 27/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8897\n",
      "Epoch 28/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8414\n",
      "Epoch 29/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8828\n",
      "Epoch 30/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8897\n",
      "Epoch 31/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8552\n",
      "Epoch 32/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8897\n",
      "Epoch 33/120\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8828\n",
      "Epoch 34/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.9034\n",
      "Epoch 35/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2953 - accuracy: 0.8966\n",
      "Epoch 36/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.8966\n",
      "Epoch 37/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2796 - accuracy: 0.9103\n",
      "Epoch 38/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.2764 - accuracy: 0.8828\n",
      "Epoch 39/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2700 - accuracy: 0.9103\n",
      "Epoch 40/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.9103\n",
      "Epoch 41/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.2593 - accuracy: 0.8897\n",
      "Epoch 42/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2551 - accuracy: 0.9172\n",
      "Epoch 43/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.9034\n",
      "Epoch 44/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2420 - accuracy: 0.9241\n",
      "Epoch 45/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2354 - accuracy: 0.9103\n",
      "Epoch 46/120\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2493 - accuracy: 0.8828\n",
      "Epoch 47/120\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2227 - accuracy: 0.9448\n",
      "Epoch 48/120\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.2271 - accuracy: 0.9172\n",
      "Epoch 49/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2166 - accuracy: 0.9379\n",
      "Epoch 50/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2084 - accuracy: 0.9379\n",
      "Epoch 51/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.2046 - accuracy: 0.9310\n",
      "Epoch 52/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.2122 - accuracy: 0.9379\n",
      "Epoch 53/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.2184 - accuracy: 0.9034\n",
      "Epoch 54/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1904 - accuracy: 0.9586\n",
      "Epoch 55/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1930 - accuracy: 0.9586\n",
      "Epoch 56/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1924 - accuracy: 0.9448\n",
      "Epoch 57/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.9517\n",
      "Epoch 58/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1777 - accuracy: 0.9586\n",
      "Epoch 59/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1687 - accuracy: 0.9586\n",
      "Epoch 60/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1678 - accuracy: 0.9586\n",
      "Epoch 61/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1639 - accuracy: 0.9448\n",
      "Epoch 62/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1703 - accuracy: 0.9448\n",
      "Epoch 63/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.9586\n",
      "Epoch 64/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.1562 - accuracy: 0.9655\n",
      "Epoch 65/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1474 - accuracy: 0.9655\n",
      "Epoch 66/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1404 - accuracy: 0.9724\n",
      "Epoch 67/120\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1474 - accuracy: 0.9517\n",
      "Epoch 68/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1362 - accuracy: 0.9724\n",
      "Epoch 69/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9379\n",
      "Epoch 70/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1256 - accuracy: 0.9862\n",
      "Epoch 71/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9793\n",
      "Epoch 72/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1341 - accuracy: 0.9793\n",
      "Epoch 73/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.9655\n",
      "Epoch 74/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.9793\n",
      "Epoch 75/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.9862\n",
      "Epoch 76/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9793\n",
      "Epoch 77/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9724\n",
      "Epoch 78/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9793\n",
      "Epoch 79/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1099 - accuracy: 0.9724\n",
      "Epoch 80/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9724\n",
      "Epoch 81/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9862\n",
      "Epoch 82/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9862\n",
      "Epoch 83/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9793\n",
      "Epoch 84/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9862\n",
      "Epoch 85/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9793\n",
      "Epoch 86/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9931\n",
      "Epoch 87/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9862\n",
      "Epoch 88/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9862\n",
      "Epoch 89/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9862\n",
      "Epoch 90/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9862\n",
      "Epoch 91/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9862\n",
      "Epoch 92/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.9931\n",
      "Epoch 93/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0724 - accuracy: 0.9931\n",
      "Epoch 94/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9862\n",
      "Epoch 95/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 96/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0669 - accuracy: 0.9862\n",
      "Epoch 97/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9931\n",
      "Epoch 98/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0591 - accuracy: 0.9931\n",
      "Epoch 99/120\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.0590 - accuracy: 1.0000\n",
      "Epoch 100/120\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0764 - accuracy: 0.9862\n",
      "Epoch 101/120\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 102/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9931\n",
      "Epoch 103/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 1.0000\n",
      "Epoch 104/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9931\n",
      "Epoch 105/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9931\n",
      "Epoch 106/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0514 - accuracy: 1.0000\n",
      "Epoch 107/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9931\n",
      "Epoch 108/120\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 109/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 110/120\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0500 - accuracy: 1.0000\n",
      "Epoch 111/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 1.0000\n",
      "Epoch 112/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9931\n",
      "Epoch 113/120\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 114/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 115/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9931\n",
      "Epoch 116/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 117/120\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 118/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 0.9931\n",
      "Epoch 119/120\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 1.0000\n",
      "Epoch 120/120\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#모델\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# fit\n",
    "history = model.fit(X_train,y_train, epochs=120, batch_size=5)\n",
    "\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e07bdd08-fe87-4ed4-a96b-cf34fd80efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c3d564c-8b54-40bd-85b0-9ed6d38fc389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.8413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.455891877412796, 0.841269850730896]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3efc4-ae78-46b1-bdab-e0c5aeec1b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 5ms/step - loss: 0.7018 - accuracy: 0.5348\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6804 - accuracy: 0.5348\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.5348\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.6471\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6297 - accuracy: 0.6845\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.7433\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5769 - accuracy: 0.7380\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5517 - accuracy: 0.7754\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7540\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5030 - accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7487\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7968\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.8235\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8235\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.8449\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8235\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4059 - accuracy: 0.8449\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8449\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8449\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8449\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8449\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3423 - accuracy: 0.8930\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8663\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.9091\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3246 - accuracy: 0.8503\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8610\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2996 - accuracy: 0.8984\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2916 - accuracy: 0.9091\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2904 - accuracy: 0.9037\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2803 - accuracy: 0.9198\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.2898 - accuracy: 0.8824\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2816 - accuracy: 0.8930\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.8984\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2595 - accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2567 - accuracy: 0.9305\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2577 - accuracy: 0.9144\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2464 - accuracy: 0.9358\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2609 - accuracy: 0.8877\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2436 - accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2377 - accuracy: 0.9305\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2370 - accuracy: 0.9144\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2392 - accuracy: 0.9144\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2314 - accuracy: 0.9251\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2137 - accuracy: 0.9305\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2224 - accuracy: 0.9465\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2078 - accuracy: 0.9519\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2048 - accuracy: 0.9465\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2168 - accuracy: 0.9198\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2118 - accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1978 - accuracy: 0.9465\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2117 - accuracy: 0.9251\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1884 - accuracy: 0.9519\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9465\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1816 - accuracy: 0.9465\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1798 - accuracy: 0.9412\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1786 - accuracy: 0.9519\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.9465\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1780 - accuracy: 0.9412\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.9519\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.1564 - accuracy: 0.9572\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1609 - accuracy: 0.9465\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1513 - accuracy: 0.9519\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.1600 - accuracy: 0.9519\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1496 - accuracy: 0.9572\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9465\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1428 - accuracy: 0.9519\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9626\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1354 - accuracy: 0.9626\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1357 - accuracy: 0.9572\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.9572\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1213 - accuracy: 0.9786\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1337 - accuracy: 0.9626\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9465\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9465\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9626\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1016 - accuracy: 0.9733\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9679\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9840\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9786\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0899 - accuracy: 0.9893\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9893\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9893\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9947\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.1374 - accuracy: 0.9524\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 3ms/step - loss: 0.6963 - accuracy: 0.4813\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6713 - accuracy: 0.5775\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.6539 - accuracy: 0.6471\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.6356 - accuracy: 0.6898\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6113 - accuracy: 0.7059\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5850 - accuracy: 0.7326\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7219\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.5369 - accuracy: 0.7647\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7701\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.8128\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7807\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.8289\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.8235\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.4274 - accuracy: 0.8128\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.4137 - accuracy: 0.8289\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4014 - accuracy: 0.8449\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8289\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.3838 - accuracy: 0.8449\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8449\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.7968\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8396\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8289\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8556\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.8610\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8717\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8877\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8663\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8770\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8984\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8717\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.8824\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.9037\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2693 - accuracy: 0.9091\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.8877\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.8984\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.9037\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9251\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.9251\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2392 - accuracy: 0.9144\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9305\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9037\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2380 - accuracy: 0.9198\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9358\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9198\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9198\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.9412\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2002 - accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9358\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9305\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9519\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1789 - accuracy: 0.9572\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1870 - accuracy: 0.9305\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9412\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9465\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9572\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9572\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1647 - accuracy: 0.9465\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9519\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9358\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1465 - accuracy: 0.9519\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1517 - accuracy: 0.9626\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9572\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9572\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9626\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9572\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1263 - accuracy: 0.9733\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1204 - accuracy: 0.9626\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9626\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9679\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9519\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0958 - accuracy: 0.9733\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9786\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9840\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9786\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9893\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9893\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9947\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9893\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 0.9893\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9947\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3277 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 3ms/step - loss: 0.6713 - accuracy: 0.6738\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.7112\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.7112\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7540\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7487\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7380\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7594\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.8128\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7968\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.8182\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.8075\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.8021\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8396\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8128\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8075\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8128\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8128\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8396\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3813 - accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8396\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7754\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8877\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8503\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8503\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8503\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8503\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8503\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8717\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8717\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3542 - accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8663\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.9037\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3284 - accuracy: 0.8663\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8770\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.8824\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3018 - accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8930\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.9091\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2949 - accuracy: 0.8663\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2732 - accuracy: 0.8984\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.9091\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.9037\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.8930\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2699 - accuracy: 0.8984\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.8877\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.9091\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9198\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2381 - accuracy: 0.8930\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.9198\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2331 - accuracy: 0.9091\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9198\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9198\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2143 - accuracy: 0.9305\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9305\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9251\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9037\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1979 - accuracy: 0.9358\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1962 - accuracy: 0.9305\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9465\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9305\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9412\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9358\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1802 - accuracy: 0.9358\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9412\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1701 - accuracy: 0.9519\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9465\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.9519\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9519\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9358\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9358\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9519\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9412\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9412\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9626\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9572\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9679\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9626\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1270 - accuracy: 0.9679\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9626\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9679\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1292 - accuracy: 0.9519\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9626\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9733\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9733\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9572\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9572\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9733\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9733\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9786\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9840\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9893\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9733\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.3990 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 4ms/step - loss: 0.6890 - accuracy: 0.5401\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.5936\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6627 - accuracy: 0.5882\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.7005\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7219\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7647\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7380\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.8342\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.8021\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7914\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8449\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8449\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8556\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8556\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8449\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8449\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3688 - accuracy: 0.8556\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3566 - accuracy: 0.8824\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.8342\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8824\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8075\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8717\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8984\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8770\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3078 - accuracy: 0.8770\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8824\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2849 - accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8717\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8877\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.8930\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2627 - accuracy: 0.9037\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9144\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9091\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.8877\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2440 - accuracy: 0.9091\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.9144\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9198\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9037\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2072 - accuracy: 0.9358\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2125 - accuracy: 0.9412\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2062 - accuracy: 0.9412\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2004 - accuracy: 0.9305\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9305\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9305\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1836 - accuracy: 0.9358\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1809 - accuracy: 0.9358\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9519\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1778 - accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9465\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9465\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9305\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9465\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9572\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9679\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1535 - accuracy: 0.9626\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9679\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9519\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9679\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9519\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9733\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9786\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9786\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 0.9733\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9786\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9679\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9840\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9733\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9733\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9840\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9840\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9893\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9840\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9840\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9786\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.9626\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9893\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9893\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9893\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9893\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.7699 - accuracy: 0.6667\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 1s 3ms/step - loss: 0.6864 - accuracy: 0.5508\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.6043\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.6471\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.7219\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7487\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7807\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7861\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7968\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7968\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.8021\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7754\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8075\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8396\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8235\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8128\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8289\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8342\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8289\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8396\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8396\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8075\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8449\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8235\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8663\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8930\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.8930\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.8930\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2749 - accuracy: 0.8824\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8717\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2690 - accuracy: 0.8984\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9037\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.8877\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.9037\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2508 - accuracy: 0.9037\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.9037\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2513 - accuracy: 0.8877\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9037\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9037\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2220 - accuracy: 0.9412\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9251\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2147 - accuracy: 0.9305\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9305\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9198\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2097 - accuracy: 0.9091\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1963 - accuracy: 0.9251\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9305\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9358\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9305\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9358\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1840 - accuracy: 0.9144\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9412\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1707 - accuracy: 0.9412\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9465\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1629 - accuracy: 0.9519\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1611 - accuracy: 0.9465\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9358\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9305\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9519\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9519\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1516 - accuracy: 0.9358\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9037\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9465\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9412\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.9572\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9626\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9519\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.9465\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9626\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9626\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9626\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9626\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9519\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.9572\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9626\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9786\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9679\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0969 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9893\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9733\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9679\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9733\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.9786\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9786\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9786\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9893\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9893\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9840\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9733\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9786\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9947\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9840\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9893\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.9073 - accuracy: 0.8571\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 3ms/step - loss: 0.6955 - accuracy: 0.5348\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.5348\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5348\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.5508\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.5561\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.5882\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.5775\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.6578\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6524\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7701\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7005\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7326\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7647\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7968\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7861\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7968\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7968\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8075\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.8128\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7861\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7807\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8503\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8556\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8396\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3816 - accuracy: 0.8503\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8289\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8770\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8449\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8610\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8663\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8824\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8877\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8556\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8663\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8824\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3162 - accuracy: 0.8556\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8663\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8824\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8877\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8930\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2768 - accuracy: 0.8930\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2718 - accuracy: 0.9037\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9091\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 0.9144\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8984\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.9198\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.8877\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2419 - accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.8984\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.9144\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2184 - accuracy: 0.9198\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2252 - accuracy: 0.9037\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9091\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2228 - accuracy: 0.9198\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9198\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2028 - accuracy: 0.9358\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9305\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1895 - accuracy: 0.9519\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1878 - accuracy: 0.9465\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1767 - accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9198\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.9572\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9572\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9626\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9572\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9519\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9572\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1543 - accuracy: 0.9679\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9786\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9519\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1404 - accuracy: 0.9572\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.9679\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9679\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9679\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1222 - accuracy: 0.9679\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.1064 - accuracy: 0.9840\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9840\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9786\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1037 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9733\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9679\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9840\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9893\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9947\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0814 - accuracy: 0.9786\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9893\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0729 - accuracy: 0.9786\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9947\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9947\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.2771 - accuracy: 0.9048\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 3ms/step - loss: 0.6887 - accuracy: 0.5294\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.6471\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.6631\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6381 - accuracy: 0.6738\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6952\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7059\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6952\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7647\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7433\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7968\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.5135 - accuracy: 0.7914\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.4781 - accuracy: 0.7647\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7807\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.8235\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.8021\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.8449\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8342\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8075\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8396\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7968\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8449\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8235\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8556\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8717\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8342\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8396\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8449\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8663\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8449\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8717\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8663\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8449\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8556\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8824\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8877\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8342\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8824\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8717\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3057 - accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.8824\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3026 - accuracy: 0.8877\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.8877\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.9091\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8717\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.9091\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.8984\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8877\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2905 - accuracy: 0.8770\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8984\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2610 - accuracy: 0.9251\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.9144\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.9251\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9091\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9091\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.9251\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.9251\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2389 - accuracy: 0.9144\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2418 - accuracy: 0.9251\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9305\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9144\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.8984\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2175 - accuracy: 0.9251\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9412\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2192 - accuracy: 0.9519\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9412\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9251\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9091\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2018 - accuracy: 0.9465\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9412\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9465\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9251\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9465\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9412\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9519\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9626\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9465\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1685 - accuracy: 0.9519\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1674 - accuracy: 0.9572\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9626\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9251\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9465\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9519\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9519\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9679\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9626\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9733\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9679\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1412 - accuracy: 0.9626\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1385 - accuracy: 0.9786\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9626\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1346 - accuracy: 0.9733\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9572\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1326 - accuracy: 0.9679\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9626\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.3465 - accuracy: 0.8095\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 4ms/step - loss: 0.6931 - accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6524\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7112\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7326\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7754\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7701\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7807\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7701\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.8075\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7914\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8021\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7914\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7861\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8289\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8289\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.7914\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8182\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8449\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3753 - accuracy: 0.8610\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8449\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.7914\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8663\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8449\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8610\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8663\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8770\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8717\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8663\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3119 - accuracy: 0.8717\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8930\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8396\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.9091\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8930\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8770\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.9144\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.9091\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2802 - accuracy: 0.8717\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9144\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.9198\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.8984\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9144\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9091\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2312 - accuracy: 0.9251\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2304 - accuracy: 0.9198\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2252 - accuracy: 0.9358\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2116 - accuracy: 0.9251\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.9358\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9305\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9144\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9305\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.9358\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1881 - accuracy: 0.9412\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9572\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9358\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9305\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1700 - accuracy: 0.9465\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1660 - accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9626\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9572\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9572\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9626\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9626\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9412\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9465\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9626\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.9626\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1284 - accuracy: 0.9572\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9679\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9679\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9679\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9786\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9733\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9679\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9733\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9786\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9733\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9840\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0883 - accuracy: 0.9840\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9893\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9840\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9893\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9840\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9840\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0742 - accuracy: 0.9893\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9947\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9947\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9947\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9893\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9893\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9947\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9947\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9947\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9947\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9947\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "tf.random.set_seed(3)\n",
    "# X,y\n",
    "X=df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]\n",
    "n_fold = 10\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=10)\n",
    "y[[0,1]]\n",
    "accuracy = []\n",
    "# skf.split(X, y)\n",
    "for train, test in skf.split(X, y):\n",
    "#     print(X[train])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(24, input_dim=60, activation='relu'))\n",
    "\tmodel.add(Dense(10, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\tmodel.fit(X.iloc[train, :], y[train], epochs=100, batch_size=5)\n",
    "\n",
    "\tk_accuracy = \"%.4f\" % (model.evaluate(X.iloc[test, :], y[test])[1])\n",
    "\taccuracy.append(k_accuracy)\n",
    "\n",
    "print(\"\\n %.f fold accuracy: \" % n_fold, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c64f2c-6b08-47a4-a8fa-23b1aaf7533a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
